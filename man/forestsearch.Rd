% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/forest_search.R, R/forestsearch_helpers.R
\name{forestsearch}
\alias{forestsearch}
\alias{print.forestsearch}
\alias{summary.forestsearch}
\title{Forest Search for Subgroup Identification in Survival Analysis}
\usage{
forestsearch(
  df.analysis,
  outcome.name = "tte",
  event.name = "event",
  treat.name = "treat",
  id.name = "id",
  potentialOutcome.name = NULL,
  flag_harm.name = NULL,
  confounders.name = NULL,
  parallel_args = list(plan = "callr", workers = 6, show_message = TRUE),
  df.predict = NULL,
  df.test = NULL,
  is.RCT = TRUE,
  seedit = 8316951,
  est.scale = "hr",
  use_lasso = TRUE,
  use_grf = TRUE,
  grf_res = NULL,
  grf_cuts = NULL,
  max_n_confounders = 1000,
  grf_depth = 2,
  dmin.grf = 12,
  frac.tau = 0.6,
  conf_force = NULL,
  defaultcut_names = NULL,
  cut_type = "default",
  exclude_cuts = NULL,
  replace_med_grf = FALSE,
  cont.cutoff = 4,
  conf.cont_medians = NULL,
  conf.cont_medians_force = NULL,
  n.min = 60,
  hr.threshold = 1.25,
  hr.consistency = 1,
  sg_focus = "hr",
  fs.splits = 1000,
  m1.threshold = Inf,
  pconsistency.threshold = 0.9,
  showten_subgroups = FALSE,
  d0.min = 12,
  d1.min = 12,
  max.minutes = 3,
  minp = 0.025,
  details = FALSE,
  maxk = 2,
  by.risk = 12,
  plot.sg = FALSE,
  plot.grf = FALSE,
  max_subgroups_search = 10,
  vi.grf.min = -0.2
)

\method{print}{forestsearch}(x, ...)

\method{summary}{forestsearch}(object, ...)
}
\arguments{
\item{df.analysis}{Data frame containing the analysis dataset with required columns:
\itemize{
\item \code{Y}: Numeric. Observed survival time or time to event
\item \code{Event}: Binary (0/1). Event indicator (1 = event occurred)
\item \code{Treat}: Binary (0/1). Treatment assignment (1 = treatment, 0 = control)
\item \code{id}: Patient identifier (numeric or character)
\item Additional covariate columns for subgroup discovery
}}

\item{n.min}{Integer. Minimum total sample size for valid subgroup. Default = 60.
Ensures statistical stability and clinical relevance.
Recommendations by study size:
\itemize{
\item Small trials (N<300): 30-50
\item Medium trials (N=300-1000): 60-80
\item Large trials (N>1000): 100+
}}

\item{hr.threshold}{Numeric. Minimum hazard ratio for initial subgroup consideration.
Default = 1.25 (25\\% increased hazard). Range: 1.0 to 2.0+.
Lower values (1.1-1.2) for safety surveillance or exploratory studies.
Higher values (1.4-1.5+) for confirmatory trials or specific signatures.
Interacts with sg_focus: use lower thresholds with "maxSG", higher with "minSG".}

\item{hr.consistency}{Numeric. Minimum hazard ratio required in split-sample validation.
Default = 1.0 (any harmful effect). Range: 0.8 to 1.5.
Controls validation stringency:
\itemize{
\item 0.8-0.9: Allows 10-20\\% effect attenuation
\item 1.0: Effect must persist (no attenuation)
\item 1.1+: Effect must maintain minimum clinical significance
}}

\item{sg_focus}{Character. Determines subgroup prioritization strategy when multiple
candidates meet consistency criteria. Options:
\describe{
\item{"hr"}{(Default) Prioritizes most reliable harm signal. Selection order:
highest consistency (Pcons), largest hazard ratio, fewest factors.
Best for: regulatory submissions, confirmatory trials, academic publications.}
\item{"maxSG"}{Prioritizes largest affected population. Selection order:
largest sample size, highest consistency, fewest factors.
Best for: public health decisions, treatment guidelines, population protection.}
\item{"minSG"}{Prioritizes most specific/smallest subgroup. Selection order:
smallest sample size, highest consistency, fewest factors.
Best for: precision medicine, biomarker signatures, targeted interventions.}
\item{"hrMaxSG"}{Among subgroups with HR > hr.threshold, selects largest.
Two-stage: filter by effect size, then maximize coverage.
Best for: clinical guidelines balancing effect and impact.}
\item{"hrMinSG"}{Among subgroups with HR > hr.threshold, selects most specific.
Two-stage: filter by effect size, then maximize specificity.
Best for: companion diagnostics, ultra-high-risk identification.}
}}

\item{pconsistency.threshold}{Numeric. Minimum proportion of random splits where both
halves show HR > hr.consistency. Default = 0.90 (90\\% of splits).
Range: 0.5 to 0.95+. Controls reproducibility:
\itemize{
\item 0.70-0.80: Exploratory, hypothesis-generating
\item 0.85-0.90: Standard confirmatory analysis
\item 0.95+: Regulatory submission, high confidence required
}}

\item{d0.min}{Integer. Minimum events required in control arm of subgroup.
Default = 15. Ensures stable baseline hazard estimation.}

\item{d1.min}{Integer. Minimum events required in treatment arm of subgroup.
Default = 15. Ensures stable treatment effect estimation.}

\item{details}{Logical. Print detailed progress messages during execution.
Default = TRUE. Set FALSE for silent operation or simulation studies.}

\item{maxk}{Integer. Maximum number of factors allowed in a subgroup definition.
Default = 2. Range: 1-5. Higher values allow more complex interactions but
increase multiple testing and reduce interpretability.}

\item{n.splits}{Integer. Number of random 50/50 splits for consistency evaluation.
Default = 1000. Range: 500-5000. More splits increase precision but computation time.}

\item{stop.threshold}{Numeric. Early stopping threshold for consistency.
Default = NULL (no early stopping) or same as pconsistency.threshold.
If specified, stops evaluation when impossible to achieve pconsistency.threshold.}

\item{nmin.grf}{Integer. Minimum node size for GRF variable importance calculation.
Default = 60. Smaller values allow more granular splits but may overfit.}

\item{n_a_s}{Numeric vector. Sample size allocation for bootstrap samples.
Default = c(1/3, 1/3, 1/3) for three equal parts.
Must sum to 1. First element for discovery, second for validation, third for testing.}

\item{conf.type}{Character. Confidence interval type for hazard ratio estimates:
\describe{
\item{"approximate"}{Cox model-based Wald confidence intervals (fastest)}
\item{"bootstrap"}{Bootstrap confidence intervals (most accurate)}
\item{"biascorrected"}{Bias-corrected bootstrap intervals (recommended)}
}}

\item{n.boot}{Integer. Number of bootstrap samples for confidence intervals.
Default = 1000. Only used if conf.type includes "bootstrap".
Range: 500-10000. Higher values increase precision but computation time.}

\item{parallel}{Logical. Enable parallel processing for bootstrap iterations.
Default = FALSE. Requires setup of parallel backend (e.g., doParallel).}

\item{n.cores}{Integer. Number of CPU cores for parallel processing.
Default = NULL (uses all available cores - 1).
Only used if parallel = TRUE.}

\item{seed}{Integer. Random seed for reproducibility. Default = NULL.
Set explicit seed for reproducible results across runs.}

\item{conf.factor}{Character vector. Names of factors to force into all models.
Default = NULL. Use for known important confounders or stratification factors.}

\item{LassoCV_method}{Character. Cross-validation method for LASSO:
"min" (minimum CV error) or "1se" (one standard error rule).
Default = "min" for maximum predictive accuracy.}
}
\value{
A list of class "forestsearch" containing:
\describe{
\item{sg.harm}{Primary selected subgroup based on sg_focus criterion}
\item{fs.est}{Forest search point estimates and model details}
\item{grp.consistency}{Consistency evaluation results for all sg_focus options:
\itemize{
\item out_hr: Results sorted by statistical reliability
\item out_maxSG: Results sorted by size (largest first)
\item out_minSG: Results sorted by size (smallest first)
}}
\item{bias_corrected}{Bias-corrected estimates (if conf.type = "biascorrected")}
\item{bootstrap_results}{Full bootstrap distribution (if n.boot > 0)}
\item{grf_importance}{Variable importance scores from GRF}
\item{lasso_selected}{Variables selected by LASSO}
\item{subgroup_definition}{Character string defining selected subgroup}
\item{consistency_metrics}{Detailed consistency statistics}
\item{parameters}{List of all input parameters for reproducibility}
\item{computation_time}{Elapsed time for major computational steps}
}
}
\description{
Implements a comprehensive statistical framework for identifying subgroups with
differential treatment effects in survival analysis. The method combines Generalized
Random Forests (GRF) for variable selection, LASSO regularization for dimension
reduction, exhaustive combinatorial search for subgroup discovery, and bootstrap
bias correction for robust inference. The function employs split-sample validation
to ensure reproducibility and control Type I error.
}
\details{
\strong{Algorithm Overview:}
\enumerate{
\item \strong{Variable Selection}: GRF identifies variables with potential
treatment effect heterogeneity
\item \strong{Dimension Reduction}: LASSO selects most predictive variables
\item \strong{Subgroup Discovery}: Exhaustive search over combinations up to maxk
\item \strong{Consistency Validation}: Split-sample validation with n.splits iterations
\item \strong{Selection}: Choose subgroup based on sg_focus criterion
\item \strong{Inference}: Bootstrap for bias correction and confidence intervals
}

\strong{Statistical Considerations:}
\itemize{
\item Controls Type I error through split-sample validation
\item Addresses overfitting via consistency requirements
\item Handles multiple testing through validation framework
\item Provides bias-corrected estimates for selected subgroups
}

\strong{Computational Notes:}
\itemize{
\item Computation scales with: n.splits × n.boot × number of candidate subgroups
\item Parallel processing recommended for n.boot > 500
\item Memory usage proportional to data size and maxk
\item Progress bars available when details = TRUE
}
}
\examples{
\dontrun{
# Example 1: Regulatory submission with high reliability focus
result_regulatory <- forestsearch(
  df.analysis = trial_data,
  sg_focus = "hr",                    # Maximum reliability
  hr.threshold = 1.3,                 # Clinically meaningful
  hr.consistency = 1.15,              # Must maintain effect
  pconsistency.threshold = 0.95,      # Very high confidence
  n.min = 100,
  d0.min = 25,
  d1.min = 25,
  n.splits = 2000,                    # Extra validation
  conf.type = "biascorrected",
  n.boot = 1000,
  parallel = TRUE,
  seed = 123
)

# Example 2: Public health application with population focus
result_public <- forestsearch(
  df.analysis = population_data,
  sg_focus = "maxSG",                 # Maximize coverage
  hr.threshold = 1.15,                # Lower threshold
  hr.consistency = 0.95,              # Some attenuation OK
  pconsistency.threshold = 0.85,      # Moderate confidence
  n.min = 80,
  d0.min = 20,
  d1.min = 20,
  conf.type = "approximate"           # Faster computation
)

# Example 3: Biomarker discovery with specificity focus
result_biomarker <- forestsearch(
  df.analysis = biomarker_data,
  sg_focus = "hrMinSG",               # Specific + harmful
  hr.threshold = 2.0,                 # High effect required
  hr.consistency = 1.5,               # Strong validation
  pconsistency.threshold = 0.90,
  n.min = 25,                         # Allow small subgroups
  d0.min = 7,
  d1.min = 7,
  maxk = 4,                           # Complex signatures OK
  conf.type = "bootstrap",
  n.boot = 2000
)

# Example 4: Sensitivity analysis across sg_focus options
sg_options <- c("hr", "maxSG", "minSG", "hrMaxSG", "hrMinSG")
sensitivity_results <- lapply(sg_options, function(focus) {
  forestsearch(
    df.analysis = trial_data,
    sg_focus = focus,
    hr.threshold = 1.25,
    details = FALSE
  )
})

# Compare selected subgroups
comparison <- data.frame(
  sg_focus = sg_options,
  N = sapply(sensitivity_results, function(x) x$sg.harm$N),
  HR = sapply(sensitivity_results, function(x) x$sg.harm$hr),
  Pcons = sapply(sensitivity_results, function(x) x$sg.harm$Pcons)
)
print(comparison)
}

}
\references{
\itemize{
\item FDA Guidance for Industry: Enrichment Strategies for Clinical Trials
to Support Approval of Human Drugs and Biological Products (2019)
\item EMA Guideline on the investigation of subgroups in confirmatory
clinical trials (2019)
\item Lipkovich et al. (2011). Subgroup identification based on differential
effect search - A recursive partitioning method for establishing response
to treatment in patient subpopulations. Statistics in Medicine.
\item Athey & Imbens (2016). Recursive partitioning for heterogeneous
causal effects. PNAS.
\item Wager & Athey (2018). Estimation and inference of heterogeneous
treatment effects using random forests. JASA.
}
}
\seealso{
\code{\link{subgroup.consistency}} for consistency evaluation details
\code{\link{bootstrap_forestsearch}} for bootstrap inference
\code{\link{summarize_forestsearch}} for results visualization
\code{\link{plot.forestsearch}} for graphical displays
}
