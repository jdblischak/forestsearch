\Sexpr{set_parent("forestSearch_SIM-Rev1_v0.Rnw")}

<<echo=FALSE>>=
opts_chunk$set (warning = FALSE, message = FALSE, tidy=TRUE, echo=FALSE, dev = 'pdf')
options(warn=-1)
@


<<echo=FALSE>>=
rm(list=ls())
library(knitr)
library(kableExtra)
library(data.table)
library(survival)

# Simulation setup
# and underlying dgm's
gbsg_cens<-round(1-mean(gbsg$status),2)

# M1 
# noise = 0
load(file="../simulations_results/oc_sims=20000_m4a-Noise=0_N=700_null_ktreat=0.9_v0A.Rdata")
res1_0_null <- res
oc1_0_null <- oc.tab
dgm1_null <- dgm
p1_Any_null <- round(pAnyH.approx2,3)
hr1_null_itt <- round(dgm$hr.Hc.true,2)

# m1 alternative
load(file="../simulations_results/oc_sims=20000_m4a-Noise=0_N=700_alt_ktreat=0.9_hrH=2_v0A.Rdata")
res1_0_alt <- res
oc1_0_alt <- oc.tab
dgm1_alt <- dgm
p1_Any_alt <- round(pAnyH.approx2,2)
pH1 <- round(100*mean(dgm$df.super_rand$flag.harm),0)
nH1 <- round(700*mean(dgm$df.super_rand$flag.harm),0)
hr1_H <- round(dgm$hr.H.true,2)
hr1_Hc <- round(dgm$hr.Hc.true,2)
hr1_itt <- round(dgm$hr.causal,2) 


# M2 
# noise = 0
load(file="../simulations_results/oc_sims=20000_m4aB-Noise=0_N=500_null_ktreat=0.9_v0A.Rdata")
res2_0_null <- res
oc2_0_null <- oc.tab
dgm2_null <- dgm
p2_Any_null <- round(pAnyH.approx2,3)
hr2_null_itt <- round(dgm$hr.Hc.true,2)

# m2 alternative
load(file="../simulations_results/oc_sims=20000_m4aB-Noise=0_N=500_alt_ktreat=0.9_hrH=2_v0A.Rdata")
res2_0_alt <- res
oc2_0_alt <- oc.tab
dgm2_alt <- dgm
p2_Any_alt <- round(pAnyH.approx2,2)
pH2 <- round(100*mean(dgm$df.super_rand$flag.harm),0)
nH2 <- round(500*mean(dgm$df.super_rand$flag.harm),0)
hr2_H <- round(dgm$hr.H.true,2)
hr2_Hc <- round(dgm$hr.Hc.true,2)
hr2_itt <- round(dgm$hr.causal,2) 


# M3 
# noise = 0
load(file="../simulations_results/oc_sims=20000_m4c-Noise=0_N=300_null_ktreat=1.5_v0A.Rdata")
res3_0_null <- res
oc3_0_null <- oc.tab
dgm3_null <- dgm
p3_Any_null <- round(pAnyH.approx2,3)
hr3_null_itt <- round(dgm$hr.Hc.true,2)

# m3 alternative
load(file="../simulations_results/oc_sims=20000_m4c-Noise=0_N=300_alt_ktreat=1.5_hrH=2_v0A.Rdata")
res3_0_alt <- res
oc3_0_alt <- oc.tab
dgm3_alt <- dgm
p3_Any_alt <- round(pAnyH.approx2,2)
pH3 <- round(100*mean(dgm$df.super_rand$flag.harm),0)
nH3 <- round(300*mean(dgm$df.super_rand$flag.harm),0)
hr3_H <- round(dgm$hr.H.true,2)
hr3_Hc <- round(dgm$hr.Hc.true,2)
hr3_itt <- round(dgm$hr.causal,2) 

# Censoring in simulations
# Censoring is identical regardless of analysis
temp <- subset(res1_0_null,analysis=="FSl")
pcens_sims<-round(mean(temp$p.cens),2)
Nsims<-"20,000"
pH_super<-round(mean(dgm1_alt$df.super_rand$flag.harm),2)
@


<<echo=FALSE>>=
bootdir <- c("../simulations_results_bootstrap")
#simpath<-c("/media/larryleon/My Projects/GitHub/Forest-Search/paper")
#resdir<-paste0(simpath,"/simulations_results_bootstrap/N=300/")
resdir<-paste0(bootdir,"/N=300/")

indexlist<-c("1-20","21-50","51-350","351-400","401-450","451-700","701-1000")
res_all<-NULL
for(ssi in 1:length(indexlist)){
outf<-paste0("LG_noise=5_hrH=2_S=",indexlist[ssi])
outf<-paste0(outf,"_B=300_m4c_N=300_alt_ktreat=1.5_v0A.Rdata")
outf<-c(paste0(resdir,outf))
load(outf)
res<-sim_answers1
res_all<-rbind(res_all,res)
rm("res")
}
nboots3 <- nrow(na.omit(res_all))
dgm <- dgm3_alt
b_hr <- dgm$b_hr.true
aa3 <- c(b_hr["treat"])
# interaction term "gamma"
bb3 <- c(b_hr["zh"])
# hrH
#exp(aa+bb)
# hrHc
#exp(aa)
# Go back to super-population and confirm
#df_super <- dgm$df.super_rand
# Controlled direct effecs in super-population
#with(subset(df_super,flag.harm==1),mean(h1.potential)/mean(h0.potential))
#with(subset(df_super,flag.harm==0),mean(h1.potential)/mean(h0.potential))
# Conditional causal effect
#with(subset(df_super,flag.harm==1),mean(hlin.ratio))
#with(subset(df_super,flag.harm==0),mean(hlin.ratio))
# Here the same, as shown by Aalen 2015
# Check marginal Cox from super-population outcome model
#CoxH_super <- coxph(Surv(Ts,es)~treat,data=subset(df_super,flag.harm==1))
#CoxHc_super <- coxph(Surv(Ts,es)~treat,data=subset(df_super,flag.harm==0))
#cat("Marginal Cox hazard ratios: H, Hc=",c(exp(coefficients(CoxH_super)),exp(coefficients(CoxHc_super))),"\n")
@


<<echo=FALSE>>=
#simpath<-c("/media/larryleon/My Projects/GitHub/Forest-Search/paper")
#resdir<-paste0(simpath,"/simulations_results_bootstrap/N=500/")
# Where to store table output
#outdir<-simpath

resdir<-paste0(bootdir,"/N=500/")

indexlist<-c("1-20","21-40","41-70","71-100","101-260","261-600","601-650","651-800","801-950","951-1000")
res_all<-NULL
for(ssi in 1:length(indexlist)){
outf<-paste0("LG_noise=5_hrH=2_S=",indexlist[ssi])
outf<-paste0(outf,"_B=300_m4aB_N=500_alt_ktreat=0.9_v0A.Rdata")
outf<-c(paste0(resdir,outf))
load(outf)
# 5% trimming of corrected version
res<-sim_answers1
res_all<-rbind(res_all,res)
rm("res")
}

nboots2 <- nrow(na.omit(res_all))

dgm <- dgm2_alt

b_hr <- dgm$b_hr.true
aa2 <- c(b_hr["treat"])
# interaction term "gamma"
bb2 <- c(b_hr["zh"])
@


<<echo=FALSE>>=
#simpath<-c("/media/larryleon/My Projects/GitHub/Forest-Search/paper")
#resdir<-paste0(simpath,"/simulations_results_bootstrap/N=700/")
# Where to store table output
#outdir<-simpath

resdir<-paste0(bootdir,"/N=700/")

indexlist<-c("1-30","31-50","51-500","501-550","551-575","576-600","601-700","701-1000")
res_all<-NULL
for(ssi in 1:length(indexlist)){
outf<-paste0("LG_noise=3_hrH=2_S=",indexlist[ssi])
outf<-paste0(outf,"_B=300_m4a_N=700_alt_ktreat=0.9_v0A.Rdata")
outf<-c(paste0(resdir,outf))
load(outf)
# 5% trimming of corrected version
res<-sim_answers1
res_all<-rbind(res_all,res)
rm("res")
}

nboots1 <- nrow(na.omit(res_all))

dgm <- dgm1_alt

b_hr <- dgm$b_hr.true
aa1 <- c(b_hr["treat"])
# interaction term "gamma"
bb1 <- c(b_hr["zh"])
@



\subsection{FS bootstrap bias-correction and variance estimation} \label{sec:boot}

By the nature of the FS procedure we expect un-adjusted Cox model estimates based on $\widehat{H}$ to be upwardly biased due to the hazard ratio thresholds, especially for $\hplim \leq 1.25$ (Since by construction point estimates are $\geq 1.25$ for $\widehat{H}$). However the bias can also be pressured in the opposite direction depending on the proportion of $H^{c}$ subjects (incorrectly) included in $\widehat{H}$ and the value of $\hplim$ relative to $\hcplim$ (e.g., mixture of $\hplim=2.0$ vs. $\hcplim=0.65$).  In general there is potential for exacerbating estimation bias due to the subgroup selection.  For bias-correction, we proceed on the Cox regression coefficient scale, denoted $\hat\beta(\widehat{H})$, and then exponentiate to obtain point estimates and confidence intervals for hazard ratios $\hat\theta(\widehat{H}):= \exp(\hat\beta(\widehat{H}))$.

Our bias corrected estimator takes into account two sources of bias which involve the discrepancies between the bootstrapped and observed data Cox estimators, $\hat\beta^{*}_{b}(\cdot) - \hat\beta(\cdot)$ say, evaluated separately at the bootstrapped and observed subgroup estimates.   The bias corrected estimator $\hat\beta^{*}(\widehat{H})$ described below is along the lines of  Harrell et al.\cite{Harrell_1996}  However our understanding is that the latter\cite{Harrell_1996} does not involve the bias term involving $\hat\beta^{*}_{b}(\widehat{H}) - \hat\beta(\widehat{H})$.   

For the observed data with estimated subgroup $\widehat{H}$ define $\hat\beta(\widehat{H})$ as the estimated Cox model regression parameter.  Analogously, for 
bootstrap samples $b=1,\ldots,B$ with estimated subgroup $\widehat{H}^{*}_{b}$, let $\hat\beta^{*}_{b}(\widehat{H}^{*}_{b})$ 
denote the estimated Cox model parameter for the bootstrap sample based on subgroup $\widehat{H}^{*}_{b}$.  In addition, 
let $\hat\beta(\widehat{H}^{*}_{b})$ denote the Cox model parameter for the observed data based on the bootstrap estimated subgroup $\widehat{H}^{*}_{b}$ (That is, the Cox model estimate applied to the observed data within the subgroup defined by $\widehat{H}^{*}_{b}$.). 
Define $\hat\beta^{*}_{b}(\widehat{H})$ similarly and form the bias terms $\eta_{b}^{*}(\widehat{H}^{*}_{b})= \hat\beta^{*}_{b}(\widehat{H}^{*}_{b}) - \hat\beta(\widehat{H}^{*}_{b})$ and $\eta_{b}^{*}(\widehat{H})= \hat\beta^{*}_{b}(\widehat{H}) - \hat\beta(\widehat{H})$
for $\hat\beta(\widehat{H})$.  Correspondingly, for the complementary subgroup, define $\eta_{b}^{*}(\widehat{H}^{c*}_{b})$ and $\eta_{b}^{*}(\widehat{H}^{c})$ for $\hat\beta(\widehat{H}^{c})$ analogously.  Let $\{(\eta_{b}^{*}(\widehat{H}^{*}_{b})+\eta_{b}^{*}(\widehat{H})), (\eta_{b}^{*}(\widehat{H}^{c*}_{b}) + \eta_{b}^{*}(\widehat{H}^{c}))\}$ denote bootstrap samples $b=1,\ldots,B$.
The bias-corrected estimators are defined as 

\begin{equation}
\hat\beta^{*}(\widehat{H})=\hat\beta(\widehat{H})-(1/B)\sum_{b=1}^{B} (\eta_{b}^{*}(\widehat{H}^{*}_{b}) + \eta_{b}^{*}(\widehat{H})), \quad \hat\theta^{*}(\widehat{H}) = \exp(\hat\beta^{*}(\widehat{H})),
\label{Hboot_bc}
\end{equation}

\begin{equation}
\hat\beta^{*}(\widehat{H}^{c})=\hat\beta(\widehat{H}^{c})-(1/B)\sum_{b=1}^{B} (\eta_{b}^{*}(\widehat{H}^{c*}_{b}) + \eta_{b}^{*}(\widehat{H}^{c})), \quad \hat\theta^{*}(\widehat{H}^{c}) = \exp(\hat\beta^{*}(\widehat{H}^{c})).
\label{Hcboot_bc}
\end{equation}

\noindent
The bootstrap samples are drawn independently with replacement from the observed data $\{O_{i}:=(V_{i},Z_{i},Y_{i},\Delta_{i}),$ $i=1,\ldots,N \}$.   To estimate the variance we apply an infinitesimal jacknife approximation\cite{Efron_2014,Wager_2014} viewing (\ref{Hboot_bc}) and (\ref{Hcboot_bc}) as ``bagged estimators'' which has been utilized in related contexts.\cite{Rosenkranz_2016,Ballarini_2021}  

We describe the variance estimation for $\hat\beta^{*}(\widehat{H})$ given by (\ref{Hboot_bc}); the variance for the complement (\ref{Hcboot_bc}) is completely analogous.  Let $O^{*}_{b} = \{O^{*}_{b1},O^{*}_{b2},\ldots,O^{*}_{bN} \}$ denote bootstrap sample $b=1,\ldots,B$ which we write as $\{O^{*}_{bj}, j=1,\ldots,N \}$.  Let $K^{*}_{bi}=\# \{O^{*}_{bj}=O_{i}  \}$ 
denote the number of times the $i$'th observation $O_{i}$ is drawn for the $b$'th bootstrap sample, and let $\bar{K}^{*}_{i}=(1/B)\sum_{b=1}^{B}K^{*}_{bi}$.  The intinitesimal jacknife variance estimate for $\hat\beta^{*}(\widehat{H})$ is given by

\begin{equation}
\tilde{V} = \sum_{i=1}^{N} \widetilde{cov}_{i}^{2}, \quad \widetilde{cov}_{i}=(1/B)
\sum_{b=1}^{B}(K^{*}_{bi}-\bar{K}^{*}_{i})\big(\hat\beta(\widehat{H})-\eta_{b}^{*}(\widehat{H}^{*}_{b})- \eta_{b}^{*}(\widehat{H}) -\hat\beta^{*}(\widehat{H})\big),
\label{VInfJ}
\nonumber
\end{equation}

\noindent
with bias-corrected version $\hat{V}$\cite{Wager_2014} given by 

\begin{equation}
\hat{V} := \tilde{V} - \frac{N}{B} \tilde\sigma^{2}_{B}, \quad \tilde\sigma^{2}_{B}=(1/B)\sum_{b=1}^{B}\big(\hat\beta(\widehat{H})-\eta_{b}^{*}(\widehat{H}^{*}_{b}) - \eta_{b}^{*}(\widehat{H}) -\hat\beta^{*}(\widehat{H}) \big)^{2}.
\label{VInfJ_bc}
\end{equation}

In this work, the variance estimate for the bias-corrected parameter estimator will be given by $\hat{V}$ in (\ref{VInfJ_bc}) and $95\%$ confidence intervals for hazard ratios, 
$\hat\theta^{*}(\widehat{H})$ and $\hat\theta^{*}(\widehat{H}^{c})$ defined in (\ref{Hboot_bc}) and (\ref{Hcboot_bc}) respectively, will be based on standard normal approximations (exponentiated).  
For the $\fsl$ and $\fslg$ estimators the lasso and $\grfb$ algorithms are mimicked for the bootstrap versions.  In general, the variance induced by the (well-defined) candidate selection algorithm is incorporated by mimicking the algorithm in the bootstrap process.



For summarizing estimation properties we consider bias with respect to three targets described below.   Recall, the hazard function for subjects with covariate vector characteristics ${\bm Z}={\bm z}$ with treatment set to $v$ ($0$ under control, $1$ under treatment) is given by 
$\lambda_{v}(t;{\bm z})=\lambda_{0}(t)\exp(\gamma_{0}\hbox{v}+\gamma_{1} \hbox{v}z_{1}z_{3}+ {\bm\gamma_{2}}'{\bm z_{2}}),$
and define $\theta_{v}(t) = E_{{\bm Z}}{\lambda_{v}(t;{\bm Z})}$ with the expectation over the joint covariate distribution.  We define 
the {\it controlled direct effect (CDE)} of treatment as $\theta^{\ddagger} = \theta_{1}(t)/\theta_{0}(t)$,\cite{ACR_2015} and for a generic subgroup $G$, $\theta^{\ddagger}(G)$ is defined with 
the expectation restricted to $G$ (e.g., if $G$ is defined by $\{Z_{1} = 1 \} \cap \{ Z_{4}=1 \}$).    In particular, for the true subgroups $H$ and $H^{c}$, 

\begin{equation}
\theta^{\ddagger}(H) = \exp(\gamma_{0}+\gamma_{1}), \quad \hbox{and} \quad 
\theta^{\ddagger}(H^{c}) = \exp(\gamma_{0}).  
\nonumber
\end{equation}

\noindent
For estimated subgroups which will generally consist of a mixture of subjects from $H$ and $H^{c}$ we 
use the empirical sample version of the above expectations.  That is, for subjects in $\widehat{H}$ let 
$\bar\theta_{v}(t;\widehat{H}) =\lambda_{0}(t) \exp(\gamma_{0}v) \sum_{i \in \widehat{H}} \exp(\gamma_{1}\hbox{v}z_{i,1}z_{i,3}+ {\bm\gamma_{2}}'{\bm z_{i,2}})$ and define

\begin{equation}
\theta^{\ddagger}(\widehat{H}) = \bar\theta_{1}(t;\widehat{H}) / \bar\theta_{0}(t;\widehat{H}) = \exp(\gamma_{0})\frac{\sum_{i \in \widehat{H}} \exp(\gamma_{1}z_{i,1}z_{i,3}+ {\bm\gamma_{2}}'{\bm z_{i,2}})}
{\sum_{i \in \widehat{H}} \exp({\bm\gamma_{2}}'{\bm z_{i,2}})},
\label{cdeH}
\end{equation}

\noindent where recall for subjects in $H$, $z_{i,1}z_{i,3} \equiv 1$ so the above reduces to $\theta^{\ddagger}(H)$ if $\widehat{H} \equiv H$ ($\widehat{H}$ consists only of subjects in $H$).   
Similarly, define $\theta^{\ddagger}(\widehat{H}^{c})$ with $\widehat{H}$ substituted with $\widehat{H}^{c}$ in equation (\ref{cdeH}). 

Recall that for each simulated dataset the $\gamma$ parameters are (known and) fixed for each model $M_1 - M_3$, however the covariates are randomly drawn from the ``super-population''.  Therefore, 
even for two simulated datasets with the same definition of $\widehat{H} \neq H$, for example $\{Z_{1} = 1 \} \cap \{ Z_{4}=1 \}$, the $\theta^{\ddagger}(\widehat{H})$ quantities will vary for each simulated dataset due to variation in the other covariates.  The CDE's $\theta^{\ddagger}(\widehat{H})$ and $\theta^{\ddagger}(\widehat{H}^{c})$
are thus random quantities with respect to $\widehat{H}$ and the covariates.

We evaluate bias and $95\%$ CI coverage properties for the $\fslg$ estimator, as well as the oracle estimator (i.e., under the ideal scenario where the true $H$ and $H^{c}$ subgroups are known a-priori).  Let $\hknow$ denote the oracle Cox estimator, with $\hhat$ and $\hhatB$ the observed and bootstrap bias-corrected versions based on the $\fslg$ procedure, respectively.  
For each estimator $\hat\theta(H)$, $\hhat$, and $\hhatB$, we consider three targets: $\hknow$, $\theta^{\ddagger}(\widehat{H})$, and $\theta^{\dagger}(H)$.  For each estimator define 
the $\%$ relative biases: $\hat{b}^{oracle}$, $\hat{b}^{\ddagger}$, and $b^{\dagger}$ which are relative to $\hknow$, $\theta^{\ddagger}(\widehat{H})$, and $\theta^{\dagger}(H)$, respectively.  For example, for $\hhat$: $\hat{b}^{oracle} = (\hhat - \hknow)/\hknow$, 
$\hat{b}^{\ddagger} = (\hhat - \Hhplim)/ \Hhplim$, and $b^{\dagger} = (\hhat - \hplim)/\hplim$, which are multiplied by $100$ to represent $\%$ relative bias.  Define corresponding coverage measures as $\hat{C}^{oracle}$, $\hat{C}^{\ddagger}$, and $C^{\dagger}$ 
to indicate whether the $95\%$ confidence interval covers the respective target.  For example, for  $\hhatB$, $\hat{C}^{\ddagger}$ is the proportion of times the $95\%$ CI for $\hhatB$ includes (the random) $\theta^{\ddagger}(\widehat{H})$.  

Table \ref{tab:m1B-m3B} summarizes the properties of the $\fslg$ estimator under models $M_1 - M_3$ when additional noise factors are included.  Summaries are based on estimable (evaluable) realizations (across $1,000$ simulations and $B=300$ bootstraps) where $\{\hhatB, \hchatB \}$ exists. 

For the observed $\hhat$ the (average) relative bias, $b^{\dagger}$ [$\hat{b}^{\ddagger}$] ranged from approximately $9.2\%$ to $24\%$ [$9.0\%$ to $14\%$] across the $M_1 - M_3$ models; indicating a general over-estimation for Cox hazard ratios based on estimated subgroups.  In contrast, for the bias-corrected $\hhatB$,  $b^{\dagger}$ [$\hat{b}^{\ddagger}$] ranged from $-10\%$ to  $-2.4\%$ [$-11.60\%$ to $- 6.3\%$]. 
For $\hchat$, $b^{\dagger}$ [$\hat{b}^{\ddagger}$] ranged from $0.5\%$ to $5.1\%$ [$-9.7\%$ to $2.8\%$], and for $\hchatB$,  $b^{\dagger}$ [$\hat{b}^{\ddagger}$] ranged from $2.3\%$ to  $10.9\%$ [$-4.8\%$ to $4.6\%$]. 

For standard deviation and CI accuracy we summarize the results for $\hchatB$ under model $M_3$ which has the highest difference between $\hcplim = 0.56$ and $\hhcplim=0.49$.  Here the standard deviations for $\hchat$ 
are under-estimated ($0.13$ for the empirical SD's versus $0.11$ for the average of the estimated SD's) with (slight) under-coverage for $\hcplim$ ($C^{\dagger}=92\%$) and under-coverage for $\Hhcplim$ ($\hat{C}^{\ddagger}=76\%$).  In contrast, the standard deviations for $\hchatB$ are over-estimated ($0.14$ versus $0.17$) with coverage rates $C^{\dagger}=97\%$ and $\hat{C}^{\ddagger}=93\%$.

In this setting, under models $M_1 - M_3$, the bootstrap bias-corrected estimators tend to be conservative: Under-estimating both $\hplim$ and $\Hhplim$ (``conservative for harm'') while over-estimating both $\hcplim$ and $\Hhcplim$ (``conservative for benefit''), except for under model $M_3$ where $\hat{b}^{\ddagger} \approx -4.8 \%$.  In addition, the coverage rates for $\hchatB$ are $\geq 93\%$ for each target, and the oracle coverage rates ($\hat{C}^{oracle}$) for the observed and bias-corrected estimators are $\geq 95\%$. That is, the observed and bias-corrected versions of $\widehat{H}$ and $\widehat{H}^{c}$ cover ($\geq 95\%$) their respective oracle counterparts.
