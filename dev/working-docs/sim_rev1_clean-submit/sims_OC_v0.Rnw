\Sexpr{set_parent("forestSearch_SIM-Rev1_v0.Rnw")}

<<echo=FALSE>>=
opts_chunk$set (warning = FALSE, message = FALSE, tidy=TRUE, echo=FALSE, dev = 'pdf')
options(warn=-1)
@

<<echo=FALSE>>=
# Note: to get citations in R use (eg)
# cm <- citation("survival")
# print(cm, bibtex=TRUE)
#tinytex::reinstall_tinytex(repository = "illinois")

rm(list=ls())
library(knitr)
library(kableExtra)
library(data.table)
library(survival)

#codepath<-c("/media/larryleon/My Projects/GitHub/Forest-Search/R/")
#source(paste0(codepath,"source_forestsearch_v0.R"))
#source_fs_functions(file_loc=codepath)

# Simulation setup
# and underlying dgm's
gbsg_cens<-round(1-mean(gbsg$status),2)

# M1 
# noise = 0
load(file="../simulations_results/oc_sims=20000_m4a-Noise=0_N=700_null_ktreat=0.9_v0A.Rdata")
res1_0_null <- res
oc1_0_null <- oc.tab
dgm1_null <- dgm
p1_Any_null <- round(pAnyH.approx2,3)
hr1_null_itt <- round(dgm$hr.Hc.true,2)

# rmst(tau) 
# taup := plim(tau)
taup <- with(subset(res1_0_null,analysis=="GRF"),round(mean(taumax),1))
taup1_null <- taup

m1.taup <- with(subset(dgm1_null$df.super_rand,treat==1),mean(pmin(Ts,taup)))
m0.taup <- with(subset(dgm1_null$df.super_rand,treat==0),mean(pmin(Ts,taup)))
rmst1_null <- round(m1.taup - m0.taup,1)

# Surv diff (24)
S1a <- with(subset(dgm1_null$df.super_rand,treat==1),mean(Ts >= 24))
S0a <- with(subset(dgm1_null$df.super_rand,treat==0),mean(Ts >= 24))
d1_null_24 <- S1a -S0a

S1b <- with(subset(dgm1_null$df.super_rand,treat==1),mean(Ts >= 36))
S0b <- with(subset(dgm1_null$df.super_rand,treat==0),mean(Ts >= 36))
d1_null_36 <- S1b -S0b

# noise = 3
load(file="../simulations_results/oc_sims=20000_m4a-Noise=3_N=700_null_ktreat=0.9_v0A.Rdata")
oc1_3_null <- oc.tab

# m1 alternative
load(file="../simulations_results/oc_sims=20000_m4a-Noise=0_N=700_alt_ktreat=0.9_hrH=2_v0A.Rdata")
res1_0_alt <- res
oc1_0_alt <- oc.tab
dgm1_alt <- dgm
p1_Any_alt <- round(pAnyH.approx2,2)
pH1 <- round(100*mean(dgm$df.super_rand$flag.harm),0)
nH1 <- round(700*mean(dgm$df.super_rand$flag.harm),0)
hr1_H <- round(dgm$hr.H.true,2)
hr1_Hc <- round(dgm$hr.Hc.true,2)
hr1_itt <- round(dgm$hr.causal,2) 

taup <- with(subset(res1_0_alt,analysis=="GRF"),round(mean(taumax),1))
taup1_alt <- taup 

# H subgroup
H_m1.taup <- with(subset(dgm1_alt$df.super_rand,treat==1 & flag.harm==1),mean(pmin(Ts,taup)))
H_m0.taup <- with(subset(dgm1_alt$df.super_rand,treat==0 & flag.harm==1),mean(pmin(Ts,taup)))
H_rmst1_alt <- round(H_m1.taup - H_m0.taup,1)

# Surv diff (24)
S1a <- with(subset(dgm1_alt$df.super_rand,treat==1 & flag.harm==1),mean(Ts >= 24))
S0a <- with(subset(dgm1_alt$df.super_rand,treat==0 & flag.harm==1),mean(Ts >= 24))
H_d1_alt_24 <- S1a -S0a

S1b <- with(subset(dgm1_alt$df.super_rand,treat==1 & flag.harm==1),mean(Ts >= 36))
S0b <- with(subset(dgm1_alt$df.super_rand,treat==0 & flag.harm==1),mean(Ts >= 36))
H_d1_alt_36 <- S1b -S0b


# H^c subgroup
Hc_m1.taup <- with(subset(dgm1_alt$df.super_rand,treat==1 & flag.harm==0),mean(pmin(Ts,taup)))
Hc_m0.taup <- with(subset(dgm1_alt$df.super_rand,treat==0 & flag.harm==0),mean(pmin(Ts,taup)))
Hc_rmst1_alt <- round(Hc_m1.taup - Hc_m0.taup,1)

# Surv diff (24)
S1a <- with(subset(dgm1_alt$df.super_rand,treat==1 & flag.harm==0),mean(Ts >= 24))
S0a <- with(subset(dgm1_alt$df.super_rand,treat==0 & flag.harm==0),mean(Ts >= 24))
Hc_d1_alt_24 <- S1a -S0a

S1b <- with(subset(dgm1_alt$df.super_rand,treat==1 & flag.harm==0),mean(Ts >= 36))
S0b <- with(subset(dgm1_alt$df.super_rand,treat==0 & flag.harm==0),mean(Ts >= 36))
Hc_d1_alt_36 <- S1b -S0b


load(file="../simulations_results/oc_sims=20000_m4a-Noise=3_N=700_alt_ktreat=0.9_hrH=2_v0A.Rdata")
oc1_3_alt <- oc.tab

# M2 
# noise = 0
load(file="../simulations_results/oc_sims=20000_m4aB-Noise=0_N=500_null_ktreat=0.9_v0A.Rdata")
res2_0_null <- res
oc2_0_null <- oc.tab
dgm2_null <- dgm
p2_Any_null <- round(pAnyH.approx2,3)
hr2_null_itt <- round(dgm$hr.Hc.true,2)

# m2 alternative
load(file="../simulations_results/oc_sims=20000_m4aB-Noise=0_N=500_alt_ktreat=0.9_hrH=2_v0A.Rdata")
res2_0_alt <- res
oc2_0_alt <- oc.tab
dgm2_alt <- dgm
p2_Any_alt <- round(pAnyH.approx2,2)
pH2 <- round(100*mean(dgm$df.super_rand$flag.harm),0)
nH2 <- round(500*mean(dgm$df.super_rand$flag.harm),0)
hr2_H <- round(dgm$hr.H.true,2)
hr2_Hc <- round(dgm$hr.Hc.true,2)
hr2_itt <- round(dgm$hr.causal,2) 

# rmst(tau) 
# taup := plim(tau)
taup <- with(subset(res2_0_null,analysis=="GRF"),round(mean(taumax),1))
taup2_null <- taup

m1.taup <- with(subset(dgm2_null$df.super_rand,treat==1),mean(pmin(Ts,taup)))
m0.taup <- with(subset(dgm2_null$df.super_rand,treat==0),mean(pmin(Ts,taup)))
rmst2_null <- round(m1.taup - m0.taup,1)


# M3 
# noise = 0
load(file="../simulations_results/oc_sims=20000_m4c-Noise=0_N=300_null_ktreat=1.5_v0A.Rdata")
res3_0_null <- res
oc3_0_null <- oc.tab
dgm3_null <- dgm
p3_Any_null <- round(pAnyH.approx2,3)
hr3_null_itt <- round(dgm$hr.Hc.true,2)

# rmst(tau) 
# taup := plim(tau)
taup <- with(subset(res3_0_null,analysis=="GRF"),round(mean(taumax),1))
taup3_null <- taup

m1.taup <- with(subset(dgm3_null$df.super_rand,treat==1),mean(pmin(Ts,taup)))
m0.taup <- with(subset(dgm3_null$df.super_rand,treat==0),mean(pmin(Ts,taup)))
rmst3_null <- round(m1.taup - m0.taup,1)

# m3 alternative
load(file="../simulations_results/oc_sims=20000_m4c-Noise=0_N=300_alt_ktreat=1.5_hrH=2_v0A.Rdata")
res3_0_alt <- res
oc3_0_alt <- oc.tab
dgm3_alt <- dgm
p3_Any_alt <- round(pAnyH.approx2,2)
pH3 <- round(100*mean(dgm$df.super_rand$flag.harm),0)
nH3 <- round(300*mean(dgm$df.super_rand$flag.harm),0)
hr3_H <- round(dgm$hr.H.true,2)
hr3_Hc <- round(dgm$hr.Hc.true,2)
hr3_itt <- round(dgm$hr.causal,2) 


load(file="../simulations_results/oc_sims=20000_m4c-Noise=5_N=300_null_ktreat=1.5_v0A.Rdata")
oc3_5_null <- oc.tab
load(file="../simulations_results/oc_sims=20000_m4c-Noise=5_N=300_alt_ktreat=1.5_hrH=2_v0A.Rdata")
oc3_5_alt <- oc.tab


# Censoring in simulations
# Censoring is identical regardless of analysis
temp <- subset(res1_0_null,analysis=="FSl")
pcens_sims<-round(mean(temp$p.cens),2)
Nsims<-"20,000"
pH_super<-round(mean(dgm1_alt$df.super_rand$flag.harm),2)

@

\section{Simulations} \label{sec:sims}

Our simulation setting is based on the German Breast Cancer Study Group trial data (GBSG) \cite{Schumacher_1994,Sauerbrei_1999} that is available in the 
\R{} statistical software survival library.\cite{Rcran,survival-package}  The study sample size was $N=\Sexpr{nrow(gbsg)}$ and the outcome of interest 
was tumor recurrence following the addition of hormonal therapy (yes/no) in the adjuvant setting.  The observed censoring rate was $\approx \Sexpr{100*gbsg_cens}\%$ where seven baseline factors were available
including estrogen receptors (fmol/l), age (years), progesterone (prog) receptors (fmol/l), menopausal status (post vs pre), 
number of positive lymph nodes, tumor size (mm), and tumor grade (grade 1/2 vs 3).  We denote these by $W_1$ (\verb+Estrogen+), 
$W_2$ (\verb+Age+), $W_3$ (\verb+Meno+), $W_4$ (\verb+Prog+),  $W_5$ (\verb+Nodes+), $W_6$=(\verb+Size+), 
and $W_7$ (\verb+Grade+), respectively.   

In order to mimic a randomized clinical trial and to have the flexibility to simulate desired sample sizes, we first randomly drew treatment 
arms from the GBSG dataset for a large ``super-population'' of $5,000$ subjects while retaining the subjects' observed covariates.  Specifically, for two synthetic 
treatment arms $2,500$ subjects were randomly drawn with replacement (for each arm) from the $N=\Sexpr{nrow(gbsg)}$ subjects to construct a large population that mimics the 
covariate structure of the dataset.  Simulations are then based on randomly sampling from this super-population.  

The outcomes were generated from a Weibull regression model depending on prognostic baseline factors $Z_1-Z_5$ where the $H$ subgroup was generated by a treatment interaction between $Z_1$ (defined below) and $Z_3$, with $Z_3$ denoting post-menopausal status ($Z_3=W_3$). The remaining prognostic factors were $Z_{2} = I(W_{2} \leq \hbox{med}(W_{2}))$, $Z_{4} = I(W_{4} \leq \hbox{med}(W_{4}))$, and $Z_{5} = I(W_{5} \leq \hbox{med}(W_{5}))$.  In addition, $Z_6=W_6$, and $Z_7=W_7$ were observed but non-prognostic, though correlated with $Z_1-Z_5$ per the GBSG dataset.  We defined $k({p_{H}})$ such that for $Z_1=I(W_1 \leq k({p_H}))$, the proportion of subjects in the super-population subgroup with $Z_1=1$ and $Z_3=1$ was $\approx p_{H}$.

The true model was 

\begin{equation}
\log(T)=\mu+\beta_{0}\hbox{V} +  \beta_{1} \hbox{V}Z_{1}Z_{3}  + \beta_2 Z_1 + \beta_3 Z_2 + \beta_4 Z_3 + \beta_5 Z_4 + \beta_6 Z_5 + \tau \epsilon,
\label{dgm0}
\end{equation}


\noindent with $V$ denoting treatment, $\epsilon$ was from the standard extreme value distribution and $\tau$ was a dispersion parameter.  The interaction between $Z_1$ and $Z_3$ represented the subgroup H= $\{Z_{1}=1 \}\cap \{Z_{3}=1\}$ with an underlying proportion of subjects $\approx p_{H}$.  The parameters $\beta_{0}$ and $\beta_{1}$ determined the treatment effects 
where $\beta_{1}=0$ corresponds to no subgroup effect (i.e., $H=\emptyset$). 
For a simulated trial of size $N$, the average number of subjects in the $H$ subgroup was $Np_{H}$ and the average number of subjects in the 
complement $H^{c}$= $\{Z_{1}=0 \}\cup \{Z_{3}=0\}$ was $N(1-p_{H})$.  For example, we considered a scenario with $p_{H} \approx \Sexpr{100*pH_super}\%$ where the size of $H$ was relatively small but practically important and presented a challenge for the identification of $H$ and to the interpretation of an overall (ITT) treatment effect.  

Writing the above data-generating model as 

\begin{equation}
\log(T)=\mu+\beta_{0}\hbox{V}+\beta_{1}\hbox{V}Z_{1}Z_{3}+ {\bm\beta_{2}}'{\bm Z_{2}} + \tau \epsilon, 
\label{dgma}
\end{equation}

\noindent with ${\bm Z_{2}}:= (Z_1, Z_2, Z_3, Z_4, Z_5)$ and ${\bm\beta_{2}}=(\beta_2, \beta_3, \beta_4, \beta_5, \beta_6)$ defined accordingly, we denote the corresponding hazard function when treatment is set to $v$ ($0$ under control; $1$ under treatment) for subjects with given prognostic values (${\bm Z} = {\bm z}$, say) as

\begin{equation}
\lambda_{v}(t;{\bm z})=\lambda_{0}(t)\exp(\gamma_{0}\hbox{v}+\gamma_{1} \hbox{v}z_{1}z_{3}+ {\bm\gamma_{2}}'{\bm z_{2}}),
\label{dgmh}
\end{equation}

\noindent where $\gamma = - \tau \beta$, \cite{ACR_2015} say.  The parameters $\mu$, ${\bm\beta_{2}}$, and $\tau$ were based on Weibull model fits to the observed GBSG data with $\beta_0$ and $\beta_1$ then chosen to generate (marginal) hazard ratio subgroup effects of interest in the ``super-population'' (e.g., $\hplim=2.0$, and $\hcplim =0.65$).  

A covariate-dependent censoring distribution was also generated by a Weibull model analogous to (\ref{dgma}) based on the observed data in order to have a censoring rate of approximately $\Sexpr{100*pcens_sims}\%$ (however here there is no subgroup effect, $\beta_{1} \equiv 0$).

We evaluate the operating characteristics for identifying and estimating $H$ and $H^{c}$ under various sample sizes and treatment effects.  Under the null model with $\beta_{1}=0$ ($H=\emptyset$), $H^{c}$ is the ITT population with (marginal) hazard ratio $\hplimitt$. We note that for fixed $p_{H}$ as $\beta_{1} \neq 0$ varies, inducing subgroup effect $\hplim$, the overall (ITT) population effect $\hplimitt$ will also vary; 
whereas the complementary subgroup effect $\hcplim$ will remain constant.  

For identification and estimation we are targeting marginal hazard ratios for $H$ and $H^{c}$ in the super-population where subgroup analyses are based on Cox models that solely adjust for treatment.  That is, 
excepting for treatment assignment Cox model analyses are un-adjusted for covariates.   As described by Aalen et al\cite{ACR_2015} the marginal effects for $H$ and $H^{c}$ will generally differ from  their {\it controlled direct effects} which we denote by $\hhplim$ and $\hhcplim$.  From (\ref{dgmh}) note that $\hhplim = \exp(\gamma_{0}+\gamma_{1})$, and $\hhcplim = \exp(\gamma_{0})$.   When describing FS estimation properties in Section \ref{sec:boot} we will consider accuracy in terms of both $\theta^{\dagger}(.)$ and $\theta^{\ddagger}(\cdot)$.

Now, in addition to the proposed FS approach we evaluate virtual twins\cite{FTR_2011} and GRF\cite{ATW_2019,AW_2021,CZ_2023} procedures for subgroup identification.  
To account for censoring with the virtual twins approach we employ a basic ``censoring unbiased transformation''\cite{FG_2018} (Doubly-robust versions are also available\cite{SDS_2019}).  Virtual twins is implemented via the \R{} package \verb+aVirtualTwins+,\cite{vtR} and generalized random forests is implemented using the \verb+causal_survival_forest+ function in the \R{} \verb+grf+ package.\cite{grfR,SAW_2023}  When utilized in the FS algorithm lasso is implemented with the \verb+glmnet+ \R{} package.\cite{SFHT_2011}  

For GRF and virtual twins we restrict to subgroups where sample sizes are at least $60$ subjects and to a maximum tree depth of 2; subgroups are selected as follows.

\begin{enumerate}[{GRF:}]
\item{GRF targets RMST and we denote GRF as RMST based on the truncation point $\tau=\min(\tau_{0},\tau_{1})$ where $\tau_{0}$ and $\tau_1$ are the largest non-censored (event) outcomes for the control and treatment groups (respectively).
An estimated RMST benefit of (at least) $6$ months for control is required for selection of a subgroup $H$, where among tree depths of 1 and 2, the subgroup with the largest RMST benefit ($\geq 6$ months) in favor of control is selected.}
\end{enumerate}
\begin{enumerate}[{GRF.60:}]
\item{The GRF procedure employs a double-robust approach for estimating RMST that involves estimation of the censoring distribution.  As such, the choice of the truncation point can be influential.  To reduce the potential instability we consider GRF.60 which uses $\tau_{60}:= 0.6\min(\tau_{0},\tau_{1})$.}
\end{enumerate}
\begin{enumerate}[{VT(24):}]
\item{We consider the virtual twins approach targeting survival rates at $t=24$ months. A treatment effect of $\delta \geq 0.225$, in favor of control, is required for selection of $H$.}
\end{enumerate}
\begin{enumerate}[{VT(36):}]
\item{Same as $\hbox{VT(24)}$ but with $t=36$.}
\end{enumerate}

To quantify the classification properties we consider the following sensitivity and positive predictive value measures.  For 
estimated subgroup $\widehat{H}$ define ${sens}(\widehat{H})$ and ${ppv}(\widehat{H})$ as

\begin{equation}
{sens}(\widehat{H}) = \# \{i \in \widehat{H} \cap H \} / \# \{i \in H \}, \ \hbox{and} \ {ppv}(\widehat{H}) = \# \{i \in \widehat{H} \cap H \} / \# \{i \in \widehat{H} \},
\nonumber
\end{equation}
\noindent
with measures for the complement $\widehat{H}^{c}$ defined analogously. Note that there always exists ${\widehat H}^{c}$ for any procedure, since if a candidate subgroup does not meet the criteria of a procedure then $\widehat H = \emptyset$ 
and the estimated complement is set to the overall ITT population (${\widehat H}^{c}= \Omega$, say).  Under the null when no 
subgroup $H$ exists, the denominator in $sens(\widehat{H})$ is zero and the numerator in $ppv(\widehat{H})$ is zero, thus $sens(\widehat{H})$ is undefined and $ppv(\widehat{H}) \equiv 0$.


\subsection{Chance of finding any subgroup $H$} \label{sec:simsA}

In our simulation study we consider three data generation models, denoted $M_1, M_2$, and $M_3$, where performance of the methods were evaluated under null and alternative subgroup effect conditions across $20,000$ simulations.   Under each model scenario we consider the performance when the clinical factors $Z_{1}-Z_{7}$ are evaluated as well as when additional (completely random) noise factors are artificially included (e.g., $Z_{8}, Z_{9},$ and $Z_{10}$ are each independent standard normal random variables). Recall $Z_1-Z_5$ are truly prognostic ($Z_6$ and $Z_7$ are non-prognostic but correlated with the others) and the underlying subgroup is $H= \{Z_1=1 \} \cap \{Z_3=1 \}$.

Table \ref{tab:m4} displays the probabilities for identifying a subgroup $H$, denoted $any(H)$, as well as the classification rates for each analysis approach under the null ($H= \emptyset$) and alternative.  Under 
the alternative the (marginal) hazard ratio for the subgroup $H$ was $\theta^{\dagger}(H)=2.0$ for each model $M_1-M_3$.  Under the null, we consider rates above $10\%$ for falsely identifying a subgroup $H$ (type-1 error) as generally inflated; approaches where $any(H) \geq 0.10$ are bold-faced in the table.  

For model $M_1$, the first block, there were $N=700$ subjects where under the null ($H = \emptyset$, denoted ``$M_{1}$ Null'') and alternative (denoted ``$M_{1}$ alt'') the hazard ratios for the ITT population, $\theta^{\dagger}(ITT)$, were similar at $\Sexpr{hr1_null_itt}$, and $\Sexpr{hr1_itt}$, respectively. Under the alternative the proportion of subjects in the true $H$ subgroup was $p_{H} \approx \Sexpr{pH1}\%$ and the hazard ratio for $H^{c}$ was $\theta^{\dagger}(H^{c})= \Sexpr{hr1_Hc}$.   In the scenario when only real clinical factors $Z_1, \ldots, Z_7$ were included in the analysis (The first 6 columns), under the null, all 
of the approaches controlled the type-1 error at $\leq 5\%$ except $\grfa$ which was at 
$\Sexpr{round(100*c(oc1_0_null[1,"GRF"]),0)}\%$.  Under the alternative, $\fsl$ and $\fslg$ both outperform $\grfb$ (and virtual twins) with higher rates for identifying $H$ and classification accuracy. For example, for $\fslg$ the chance of identifying any $H$ was $\Sexpr{round(100*c(oc1_0_alt[1,"FSlg"]),0)}\%$ and the accuracy for correctly classifying subjects in $H$, $sens(\widehat{H})$, was $\Sexpr{round(100*c(oc1_0_alt[2,"FSlg"]),0)}\%$; whereas for $\grfb$ these rates were $\Sexpr{round(100*c(oc1_0_alt[1,"GRF.60"]),0)}\%$ and 
$\Sexpr{round(100*c(oc1_0_alt[2,"GRF.60"]),0)}\%$, respectively.   When the analysis included three additional random noise factors, columns 7-12, the type-1 error rates for the GRF approaches were both quite elevated ($\Sexpr{round(100*c(oc1_3_null[1,"GRF"]),0)}\%$, and $\Sexpr{round(100*c(oc1_3_null[1,"GRF.60"]),0)}\%$ for $\grfa$ and $\grfb$, resp.)  with 
$\fslg$ slightly elevated at $\Sexpr{round(100*c(oc1_3_null[1,"FSlg"]),0)}\%$ whereas $\fsl$ was at $\Sexpr{round(100*c(oc1_3_null[1,"FSl"]),0)}\%$.  Moreover, despite the higher type-1 error for $\grfb$, $\fsl$ and $\fslg$ both had higher classification accuracy (e.g., $sens(\widehat{H})$ was $\Sexpr{round(100*c(oc1_3_alt[2,"FSl"]),0)}\%$ [$\Sexpr{round(100*c(oc1_3_alt[2,"FSlg"]),0)}\%$] for $\fsl$ [$\fslg$] compared to $\Sexpr{round(100*c(oc1_3_alt[2,"GRF.60"]),0)}\%$ for $\grfb$).

A similar pattern to model $M_1$ is found under $M_2$ where we consider a smaller sample size but with a higher proportion of subjects in the $H$ subgroup.  Specifically, 
model $M_2$ had $N=500$ subjects where under the null and alternative $\theta^{\dagger}(ITT)$ was $\Sexpr{hr2_null_itt}$ and $\Sexpr{hr2_itt}$ (resp.), $p_{H} \approx \Sexpr{pH2}\%$ and $\theta^{\dagger}(H^{c})= \Sexpr{hr2_Hc}$.   In addition, we consider the performance when five additional random noise factors were included in the analysis.  The type-1 errors were similar to model $M_1$, however the identification and accuracy rates were higher for $H$ relative to model $M_1$ even though the incidence rate for $H$ was only moderately increased (The average size for $H$ under models $M_1$ and $M_2$ were $\Sexpr{nH1}$ and $\Sexpr{nH2}$, resp.).

Lastly, we consider a relatively smaller sample size of $N=300$ in model $M_3$ with a stronger ITT treatment effect under the null where $\theta^{\dagger}(ITT) = \Sexpr{hr3_null_itt}$.  In this scenario all the 
approaches controlled the type-1 error rates below $5\%$ except for $\grfa$ and $\grfb$ which were slightly elevated ($\Sexpr{round(100*c(oc3_5_null[1,"GRF"]),0)}\%$, and $\Sexpr{round(100*c(oc3_5_null[1,"GRF.60"]),0)}\%$, resp.) when five additional random noise factors were included in the analysis.  In this scenario $\grfa$ had the strongest performance, albeit with the aforementioned increased type-1 error rate, whereas $\fslg$ had the highest accuracy while maintaining the type-1 error at $\leq \Sexpr{round(100*c(max(oc3_0_null[1,"FSlg"],oc3_5_null[1,"FSlg"])),0)}\%$.

We note that while the accuracy for classification of $H^{c}$ subjects via $sens(\widehat{H}^{c})$ remains seemingly high in the presence of additional noise factors ($\geq 87\%$), the $\fslg$ approach was around $7\%$ higher compared to $\grfb$ for some scenarios (e.g., $96\%$ vs. $89\%$ under the $M_2$ alternative).  Though not dramatic, this could be important in clinical practice from an individual patients' perspective.

In this simulation setting when random noise factors were included in the analyses the GRF approach was more susceptible to falsely identifying subgroups especially under models $M_1$ and $M_2$.  Intuitively, with the addition of noise factors there was more opportunity to randomly form erroneous splits.  For virtual twins, the type-1 errors were not materially increased but the accuracy performance was 
generally diluted across the scenarios.  The $\fsl$ approach was the most stable with a slight decrease in performance, while $\fslg$ inherits an increased type-1 error by the utilization of $\grfb$, but to a much lesser extent than $\grfb$ itself.  In contrast, under $M_3$ when there was the strongest ITT treatment effect under the null, the type-1 errors for both GRF approaches were dramatically decreased relative to $M_1$ and $M_2$ (From $\approx 60\%$[$30\%$] for $\grfa$[$\grfb$] under $M_1$ and $M_2$ to $13\%$[$7\%$] under $M_3$.).  We conjecture that this is due to the GRF selection criteria which requires an estimated 6-month benefit in favor of control, which is less likely with a more pronounced ITT treatment effect (Note that under the nulls of $M_1-M_3$ the ITT treatment differences with respect to RMST were $\approx$ $\Sexpr{rmst1_null}$, $\Sexpr{rmst2_null}$, and $\Sexpr{rmst3_null}$ months, resp.).  Generally, for each approach under the null, the chance of forming subgroups with an estimated benefit randomly in favor of control is less likely the stronger the ITT treatment effect.  Table \ref{tab:m4} also provides the approximation (\ref{pHat_approx}) to the power for the FS procedure (see footnotes a-f) which appears reasonably accurate for models $M_1 - M_3$.
