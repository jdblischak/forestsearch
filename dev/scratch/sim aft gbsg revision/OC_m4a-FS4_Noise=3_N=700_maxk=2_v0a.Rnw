\documentclass[9pt]{article}
\usepackage{multicol}
\usepackage{amssymb,mathrsfs,graphicx}
\usepackage{enumerate}
\usepackage{amsthm}
\usepackage{lscape}
\usepackage{pdfpages}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\theoremstyle{remark}
\newtheorem{remark}{Remark}

\usepackage[colorlinks=true,linkcolor={blue},citecolor={blue},urlcolor={blue}]{hyperref}
\usepackage{longtable,ctable}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{mathptmx}
\usepackage{natbib}
\usepackage{setspace}

\usepackage[utf8]{inputenc}
\usepackage{pgf}

\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{enumerate}
\usepackage{threeparttable}


\newcommand{\R}{R}
\newcommand{\gbsg}{gbsg}

\def\FsNg{\hbox{FS}(M_{g})}

\def\hhat{\hat\theta(\hat{H})}
\def\hchat{\hat\theta(\hat{H}^{c})}
\def\hknow{\hat\theta(H)}
\def\hcknow{\hat\theta(H^{c})}
\def\hplim{\theta^{\dagger}(H)}
\def\hcplim{\theta^{\dagger}(H^{c})}


\newcommand{\indep}{\perp \!\!\! \perp}

\textheight=9.25in \textwidth=6.0in 
\topmargin=0in
\evensidemargin=0in \oddsidemargin=0in

\begin{document}

\raggedbottom

<<echo=FALSE>>=
opts_chunk$set (warning = FALSE, message = FALSE, tidy=TRUE, echo=FALSE, dev = 'pdf')
options(warn=-1)
@

<<echo=FALSE>>=

rm(list=ls())

# Get operator (parallel or serial)
get_operator <- function() {
  is_par <- foreach::getDoParWorkers() > 1
  if (is_par) {
    res <- foreach::`%dopar%`
  } else {
    res <- foreach::`%do%`
  }
  res
}

#' Parallelize arbitrary user-supplied expression
#'
#' @param expr R expression.
#' @param n Number of iterations.
#' @param seed Initial random seed.
#' @param counter Character string. Name of the loop counter variable. Default is `"i"`.
#' @param export Exported variables to be used in `expr`.
simPar <- function(expr, sims, seed, counter = "i", export) {
  `%op%` <- get_operator()
  expr <- substitute(expr)
  res <- foreach::foreach(
    i = seq_len(sims),
    .export = export,
    .packages = c("survival","grf","policytree","aVirtualTwins","randomForest","data.table","cubature","glmnet"),
    .combine = "rbind",
    .errorhandling = "pass"
  ) %op% {
    assign(counter, value = i)
    set.seed(seed + i - 1)
    eval(expr)
  }
  res
}

library(doParallel)
registerDoParallel(parallel::detectCores(logical = FALSE))

# Use common code source
# NOTE: only when NOT running in Github directory
# Otherwise, will work on Mac
#codepath<-c("/media/larryleon/My Projects/GitHub/Forest-Search/R/")
#source(paste0(codepath,"source_forestsearch_v0.R"))
#source_fs_functions(file_loc=codepath)

source("../../R/source_forestsearch_v0.R")

source_fs_functions(file_loc="../../R/")

library(cubature)
library(formatR)

library(grf)
library(policytree)

library(glmnet)


library(kableExtra)
library(knitr)
library(ggplot2)
library(gridExtra)

library(aVirtualTwins)
library(randomForest)
library(survival)

library(data.table)
library(plyr)
library(e1071)

library(cowplot)

# These are exported in simPar 
# ANY new functions or arguments will need to be added
fun_arg_list<-c("dgm","maxFollow",
"forestsearch","fs.estimates.out","vi.grf.min","dummy","subgroup.search",
"subgroup.consistency","acm.disjctif","max.minutes","ztrail","one.zero","maxk","nmin.fs","d.min","hr.threshold",
"NA.CHR.Weighted","R.Weighted","N.Weighted","hr.consistency","stop.threshold","fs.splits","m1.threshold",
"pconsistency.threshold", "confounders.name","outcome.name","id.name","treat.name",
"cox.formula.sim","cox.formula.adj.sim","event.name",  "get.FG","FG.transform","LS.int.FG","vt.subg.harm.survival",
"vt.threshold","treat.threshold","maxdepth","n.min","ntree","vt.data2",
"formatRCTDataset2","vt.estimates.out","label.analyses","grf.subg.harm.survival","grf.estimates.out","dmin.grf",
"frac.tau","get.FS","get.VT","get.GRF","grf.fs.subg","muC.adj","N","quiet")

@

<<echo=TRUE>>=

N<-700
Nsims<-20*1000

maxFollow<-84
cens.type<-"weibull"
#########################
# Forest search criteria
#########################
hr.threshold<-1.25   # Initital candidates 
hr.consistency<-1.0  # Candidates for many splits

pconsistency.threshold <- 0.9
stop.threshold <- 0.95

maxk<-2
nmin.fs<-60
pstop_futile<-0.5

# Limit timing for forestsearch
max.minutes<-3.0
m1.threshold<-Inf # Turning this off (Default)
#pconsistency.threshold<-0.70 # Minimum threshold (will choose max among subgroups satisfying)
fs.splits<-400 # How many times to split for consistency
# vi is % factor is selected in cross-validation --> higher more important
vi.grf.min<-0.2
# Null, turns off grf screening
d.min<-10 # Min number of events for both arms (d0.min=d1.min=d.min)
# default=5

##########################
# Virtual twins analysis
##########################
# Counter-factual difference (C-E) >= vt.threshold
# Large values in favor of C (control)
vt.threshold<-0.225  # For VT delta
treat.threshold<-0.0

maxdepth <- 2

n.min<-60
ntree<-1000

# GRF criteria
dmin.grf<-12.0 # For GRF delta
# Note: For CRT this represents dmin.grf/2 RMS for control (-dmin.grf/2 for treatment)
frac.tau <- 0.60

# For forestsearch algorithm
frac.tau_fs <- 0.6

label.analyses<-c("FSl","GRF","VT(24)","VT#(24)","VT(36)","VT#(36)","GRF.60")
# Classification table names
est_names<-c("$FS_{l}$","$FS_{lg}$","$GRF$","$GRF_{60}$","$VT(24)$","${VT}^{\\#}(24)$","$VT(36)$","${VT}^{\\#}(36)$")

outcome.name<-c("y.sim")
event.name<-c("event.sim")
id.name<-c("id")
treat.name<-c("treat")

cox.formula.sim<-as.formula(paste("Surv(y.sim,event.sim)~treat"))
cox.formula.adj.sim<-as.formula(paste("Surv(y.sim,event.sim)~treat+v1+v2+v3+v4+v5"))

get.FS<-TRUE
get.VT<-TRUE
get.GRF<-TRUE

fl_prefix<-c("oc_s20k_")
out.loc<-paste0("results/",fl_prefix)

# m1 -censoring adjustment
muC.adj<-log(1.5)

# 0, 3, or 5
n_add_noise <- 3

model.index<-"m4a-FS4-mk2-Noise3"
file.index<-"v0a"

k.z3<-1.0
k.treat<-0.9

hrHs<-c(0,1,1.5,2,2.5,3)

nsize<-paste0("N=",N)
treat.id<-paste0("ktreat=",k.treat)

flist_all<-NULL
f1<-NULL
# Start with null
if(hrHs[1]==0){
f1<-fl_prefix
f1<-paste0(f1,model.index,sep="_")
f1<-paste0(f1,nsize,sep="_")
f1<-paste0(f1,"null",sep="_")
f1<-paste0(f1,treat.id,sep="_")
f1<-paste0(f1,file.index,sep=".")
f1<-paste0(f1,"Rdata")
}

flist_all<-c(flist_all,f1)
if(hrHs[1]==0){
for(hh in 2:length(hrHs)){
hrH.id<-paste0("hrH=",hrHs[hh])
fh<-fl_prefix
fh<-paste0(fh,model.index,sep="_")
fh<-paste0(fh,nsize,sep="_")
fh<-paste0(fh,"alt",sep="_")
fh<-paste0(fh,treat.id,sep="_")
fh<-paste0(fh,hrH.id,sep="_")
fh<-paste0(fh,file.index,sep=".")
fh<-paste0(fh,"Rdata")
flist_all<-c(flist_all,fh)
}
}

z1_frac<-0.25 # Default model index 'm1' (The 1st quartile of z1=er)
pH_super<-0.125 # non-NULL re-defines z1_frac

if(is.null(pH_super)){
#pH_check<-with(gbsg,mean(pgr<=quantile(pgr,c(z3_frac),1,0) & er<=quantile(er,z1_frac)))
pH_check<-with(gbsg,mean(meno==0 & er<=quantile(er,z1_frac)))
cat("Underlying pH_super",c(pH_check),"\n")
}
# pH_super specified
# If pH_super then override  z1_frac and find z1_frac to yield pH_super

if(!is.null(pH_super)){
  # Approximate Z1 quantile to yield pH proportion  
  z1_q<-uniroot(propH.obj4,c(0,1),tol=0.0001,pH.target=pH_super)$root
  #pH_check<-with(gbsg,mean(pgr<=quantile(pgr,c(z3_frac),1,0) & er<=quantile(er,z1_q)))
  pH_check<-with(gbsg,mean(meno==0 & er<=quantile(er,z1_q)))
  cat("pH",c(pH_check),"\n")
  rel_error<-(pH_super-pH_check)/pH_super
  if(abs(rel_error)>=0.1) stop("pH_super approximation relative error exceeds 10%")
  z1_frac<-z1_q
  cat("Underlying pH_super",c(pH_check),"\n")
  }

# Bootstrap on log(hr) scale converted to HR (est.loghr=TRUE & est.scale="hr")
est.loghr<-TRUE
est.scale<-"hr"
t.start.all<-proc.time()[3]

# Classification table names
# Note: within tab_tests (summary.VTFS)
# we rename so that denominator in ppv(hatH) is # hatH
# Manuscript section 3.2 will be updated accordingly

stat_names<-c("any(H)","${sens}(\\hat{H})$","${sens}(\\hat{H}^{C})$",
                        "${ppv}(\\hat{H})$","${ppv}(\\hat{H}^{C})$",
                        "${avg}\\vert \\hat{H} \\vert$",
                        "${min}\\vert \\hat{H} \\vert$",
                        "${max}\\vert \\hat{H} \\vert$",
                        "${avg}\\vert \\hat{H}^{C} \\vert$",
                        "${min}\\vert \\hat{H}^{C} \\vert$",
                        "${max}\\vert \\hat{H}^{C} \\vert$")

if(!get.FS) est_names<-est_names[-c(1:3)]

@


<<r null, echo=TRUE,eval=TRUE>>=
mod.harm <- "null"
this.dgm<-get.dgm4(mod.harm=mod.harm,N=N,k.treat=k.treat,model.index=model.index,sol_tol=10^-8,
hrH.target=hrH.target,cens.type=cens.type,out.loc=out.loc,file.index=file.index,details=TRUE,parms_torand=FALSE)
dgm<-this.dgm$dgm
output.file<-this.dgm$out.file

if(!is.null(output.file) & !grepl(mod.harm,output.file)) stop("Wrong file name for mod.harm")

t.start<-proc.time()[3]
res<-simPar(
{  
ans.analyses<-oc_analyses_m4_FS4(sim)
},
sims=Nsims,
seed=8316951,
counter="sim",
export=fun_arg_list
)
t.now<-proc.time()[3]
t.min<-(t.now-t.start)/60

print(table(res$analysis))
check<-c(c(table(res$analysis))-Nsims)
if(all(check!=0)) stop("All analyses not complete")

dgm_alt<-dgm

outres<-out.results(res=res,dgm=dgm,output.file=output.file,t.min=t.min,out_analysis="FSl")

missC<-tab_tests(res=res)

pA <- as.character(round(outres$pAnyH.approx2,4))
tabsim_missC<-get_tabsim(missC=missC,pA=pA,est_names=est_names,stat_names=stat_names,mod.harm=mod.harm,Nsims=Nsims)

@

\Sexpr{tabsim_missC}


<<r hrh2, echo=TRUE,eval=TRUE>>=
mod.harm <- "alt"
hrH.target <- 2.0
this.dgm<-get.dgm4(mod.harm=mod.harm,N=N,k.treat=k.treat,model.index=model.index,sol_tol=10^-8,
hrH.target=hrH.target,cens.type=cens.type,out.loc=out.loc,file.index=file.index,details=TRUE,parms_torand=FALSE)
dgm<-this.dgm$dgm
output.file<-this.dgm$out.file

if(!is.null(output.file) & !grepl(mod.harm,output.file)) stop("Wrong file name for mod.harm")

t.start<-proc.time()[3]
res<-simPar(
{  
ans.analyses<-oc_analyses_m4_FS4(sim)
},
sims=Nsims,
seed=8316951,
counter="sim",
export=fun_arg_list
)
t.now<-proc.time()[3]
t.min<-(t.now-t.start)/60

print(table(res$analysis))
check<-c(c(table(res$analysis))-Nsims)
if(all(check!=0)) stop("All analyses not complete")

dgm_alt<-dgm

outres<-out.results(res=res,dgm=dgm,output.file=output.file,t.min=t.min,out_analysis="FSl")

missC<-tab_tests(res=res)

pA <- as.character(round(outres$pAnyH.approx2,4))
tabsim_missC<-get_tabsim(missC=missC,pA=pA,est_names=est_names,stat_names=stat_names,mod.harm=mod.harm,Nsims=Nsims)

@

\Sexpr{tabsim_missC}



<<r hrh25, echo=TRUE,eval=TRUE>>=
mod.harm <- "alt"
hrH.target <- 2.5
this.dgm<-get.dgm4(mod.harm=mod.harm,N=N,k.treat=k.treat,model.index=model.index,sol_tol=10^-8,
hrH.target=hrH.target,cens.type=cens.type,out.loc=out.loc,file.index=file.index,details=TRUE,parms_torand=FALSE)
dgm<-this.dgm$dgm
output.file<-this.dgm$out.file

if(!is.null(output.file) & !grepl(mod.harm,output.file)) stop("Wrong file name for mod.harm")

t.start<-proc.time()[3]
res<-simPar(
{  
ans.analyses<-oc_analyses_m4_FS4(sim)
},
sims=Nsims,
seed=8316951,
counter="sim",
export=fun_arg_list
)
t.now<-proc.time()[3]
t.min<-(t.now-t.start)/60

print(table(res$analysis))
check<-c(c(table(res$analysis))-Nsims)
if(all(check!=0)) stop("All analyses not complete")

dgm_alt<-dgm

outres<-out.results(res=res,dgm=dgm,output.file=output.file,t.min=t.min,out_analysis="FSl")

missC<-tab_tests(res=res)

pA <- as.character(round(outres$pAnyH.approx2,4))
tabsim_missC<-get_tabsim(missC=missC,pA=pA,est_names=est_names,stat_names=stat_names,mod.harm=mod.harm,Nsims=Nsims)

@

\Sexpr{tabsim_missC}




<<echo=TRUE>>=
t.done<-proc.time()[3]
t.min<-(t.done-t.start.all)/60
cat("Minutes and hours to finish",c(t.min,t.min/60),"\n")
cat("Minutes and hours per 10,000 to finish",(10000/Nsims)*c(t.min,t.min/60),"\n")
cat("Machine=",c(Sys.info()[[4]]),"\n")
cat("Number of cores=",c(detectCores(logical = FALSE)),"\n")
@



\end{document}














