\documentclass[8pt]{article}
\usepackage{multicol}
\usepackage{amssymb,mathrsfs,graphicx}
\usepackage{enumerate}
\usepackage{amsthm}
\usepackage{lscape}
\usepackage{pdfpages}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\theoremstyle{remark}
\newtheorem{remark}{Remark}

\usepackage[colorlinks=true,linkcolor={blue},citecolor={blue},urlcolor={blue}]{hyperref}
\usepackage{longtable,ctable}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{mathptmx}
\usepackage{natbib}
\usepackage{setspace}

\usepackage[utf8]{inputenc}
\usepackage{pgf}

\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{enumerate}
\usepackage{threeparttable}


\newcommand{\R}{R}
\newcommand{\gbsg}{gbsg}

\def\FsNg{\hbox{FS}(M_{g})}

\def\hhat{\hat\theta(\hat{H})}
\def\hchat{\hat\theta(\hat{H}^{c})}
\def\hknow{\hat\theta(H)}
\def\hcknow{\hat\theta(H^{c})}
\def\hplim{\theta^{\dagger}(H)}
\def\hcplim{\theta^{\dagger}(H^{c})}


\newcommand{\indep}{\perp \!\!\! \perp}

\textheight=9.25in \textwidth=6.0in 
\topmargin=0in
\evensidemargin=0in \oddsidemargin=0in

\begin{document}

\raggedbottom

<<echo=FALSE>>=
opts_chunk$set (warning = FALSE, message = FALSE, tidy=TRUE, echo=FALSE, dev = 'pdf')
options(warn=-1)
@

<<echo=FALSE>>=

rm(list=ls())

library(doFuture)
library(doRNG)
registerDoFuture()
registerDoRNG()
# workers=48 works well on popOS
plan("multisession", workers=48)

# Use common code source
# NOTE: only when NOT running in Github directory
# Otherwise, will work on Mac (below when sourcing in github mac)
#codepath<-c("/media/larryleon/My Projects/GitHub/Forest-Search/R/")
#source(paste0(codepath,"source_forestsearch_v0.R"))
#source_fs_functions(file_loc=codepath)

source("../../R/source_forestsearch_v0.R")
source_fs_functions(file_loc="../../R/")

library(cubature)
#library(formatR)
library(grf)
library(policytree)
library(glmnet)
library(kableExtra)
library(knitr)
library(ggplot2)
library(gridExtra)
library(aVirtualTwins)
library(randomForest)
library(survival)
library(data.table)
library(plyr)
library(e1071)
library(benchmarkme)
#library(cli)
#library(cowplot)
@

<<echo=TRUE>>=

N <- 500
Nsims <- 200

maxFollow<-84
cens.type<-"weibull"
#########################
# Forest search criteria
#########################
hr.threshold<-1.25   # Initital candidates 
hr.consistency<-1.0  # Candidates for many splits

pconsistency.threshold <- 0.9
stop.threshold <- 0.95

maxk<-2
nmin.fs<-60
pstop_futile<-0.7

# Limit timing for forestsearch
max.minutes<-3.0
m1.threshold<-Inf # Turning this off (Default)
#pconsistency.threshold<-0.70 # Minimum threshold (will choose max among subgroups satisfying)
fs.splits<-400 # How many times to split for consistency
# vi is % factor is selected in cross-validation --> higher more important
vi.grf.min <- (-1)*0.2 # This is default (to NOT exclude via VI)
# Null, turns off grf screening
d.min<-10 # Min number of events for both arms (d0.min=d1.min=d.min)
# default=5

##########################
# Virtual twins analysis
##########################
# Counter-factual difference (C-E) >= vt.threshold
# Large values in favor of C (control)
vt.threshold<-0.225  # For VT delta
treat.threshold<-0.0

maxdepth <- 2
n.min<-60
ntree<-1000

# GRF criteria
dmin.grf<-12.0 # For GRF delta
# Note: For CRT this represents dmin.grf/2 RMS for control (-dmin.grf/2 for treatment)
frac.tau <- 0.60

# For forestsearch algorithm use same as GRF
frac.tau_fs <- 0.60
dmin.grf_fs <- 12
maxdepth_fs <- 2

label.analyses<-c("FSl","GRF","VT(24)","VT#(24)","VT(36)","VT#(36)","GRF.60")
# Classification table names
est_names<-c("$FS_{g}$","$FS_{lg}$","$GRF$","$GRF_{60}$","$VT(24)$","${VT}^{\\#}(24)$","$VT(36)$","${VT}^{\\#}(36)$")

outcome.name<-c("y.sim")
event.name<-c("event.sim")
id.name<-c("id")
treat.name<-c("treat")

cox.formula.sim<-as.formula(paste("Surv(y.sim,event.sim)~treat"))
cox.formula.adj.sim<-as.formula(paste("Surv(y.sim,event.sim)~treat+v1+v2+v3+v4+v5"))

get.FS<-TRUE
get.VT<-TRUE
get.GRF<-TRUE

fl_prefix <- paste0("oc_sims=",Nsims,"_")

out.loc<-paste0("results/",fl_prefix)

# m1 -censoring adjustment
muC.adj<-log(1.5)

# 0, 3, or 5
n_add_noise <- 5.0

mindex <- "m4aB"
file.index<-"v0-4cuts"

z1_frac <- 0.25

if(mindex=="m4a"){
k.z3 <- 1.0
k.treat <- 0.9
pH_super <- 0.125 # non-NULL re-defines z1_frac
}

if(mindex=="m4aB"){
k.z3 <- 1.0
k.treat <- 0.9
pH_super <- 0.20 # non-NULL re-defines z1_frac
}

if(mindex=="m4b"){
k.z3 <- 1.0
k.treat <- 1.25
pH_super <- 0.30 # non-NULL re-defines z1_frac
}

if(mindex=="m4c"){
k.z3 <- 1.0
k.treat <- 1.5
pH_super <- 0.30 # non-NULL re-defines z1_frac
}

model.index <- paste0(mindex,"-Noise=","")
model.index <- paste0(model.index,n_add_noise,"")

if(is.null(pH_super)){
#pH_check<-with(gbsg,mean(pgr<=quantile(pgr,c(z3_frac),1,0) & er<=quantile(er,z1_frac)))
pH_check<-with(gbsg,mean(meno==0 & er<=quantile(er,z1_frac)))
cat("Underlying pH_super",c(pH_check),"\n")
}
# pH_super specified
# If pH_super then override  z1_frac and find z1_frac to yield pH_super

if(!is.null(pH_super)){
  # Approximate Z1 quantile to yield pH proportion  
  z1_q<-uniroot(propH.obj4,c(0,1),tol=0.0001,pH.target=pH_super)$root
  #pH_check<-with(gbsg,mean(pgr<=quantile(pgr,c(z3_frac),1,0) & er<=quantile(er,z1_q)))
  pH_check<-with(gbsg,mean(meno==0 & er<=quantile(er,z1_q)))
  cat("pH",c(pH_check),"\n")
  rel_error<-(pH_super-pH_check)/pH_super
  if(abs(rel_error)>=0.1) stop("pH_super approximation relative error exceeds 10%")
  z1_frac<-z1_q
  cat("Underlying pH_super",c(pH_check),"\n")
  }

# Bootstrap on log(hr) scale converted to HR (est.loghr=TRUE & est.scale="hr")
est.loghr<-TRUE
est.scale<-"hr"
t.start.all<-proc.time()[3]

# Classification table names
# Note: within tab_tests (summary.VTFS)
# we rename so that denominator in ppv(hatH) is # hatH
# Manuscript section 3.2 will be updated accordingly

stat_names<-c("any(H)","${sens}(\\hat{H})$","${sens}(\\hat{H}^{C})$",
                        "${ppv}(\\hat{H})$","${ppv}(\\hat{H}^{C})$",
                        "${avg}\\vert \\hat{H} \\vert$",
                        "${min}\\vert \\hat{H} \\vert$",
                        "${max}\\vert \\hat{H} \\vert$",
                        "${avg}\\vert \\hat{H}^{C} \\vert$",
                        "${min}\\vert \\hat{H}^{C} \\vert$",
                        "${max}\\vert \\hat{H}^{C} \\vert$")

if(!get.FS) est_names<-est_names[-c(1:3)]

@


<<r null, echo=TRUE,eval=TRUE>>=
mod.harm <- "null"
this.dgm<-get.dgm4.OC(mod.harm=mod.harm,N=N,k.treat=k.treat,model.index=model.index,sol_tol=10^-8,
hrH.target=hrH.target,cens.type=cens.type,out.loc=out.loc,file.index=file.index,details=TRUE,parms_torand=FALSE)

dgm<-this.dgm$dgm
output.file<-this.dgm$out.file

if(!is.null(output.file) & !grepl(mod.harm,output.file)) stop("Wrong file name for mod.harm")

# Show first simulation
#ans1 <- oc_analyses_m4_FS4(1)

t.start<-proc.time()[3]
res <- foreach(
    sim = seq_len(Nsims),
    .options.future=list(seed=TRUE),
    .combine="rbind",
    .errorhandling="pass"
  ) %dofuture% {
ans <- oc_analyses_m4FourCuts_FS4(sim)
return(ans)
}
t.now<-proc.time()[3]
t.min<-(t.now-t.start)/60

print(table(res$analysis))
check<-c(c(table(res$analysis))-Nsims)
if(all(check!=0)) stop("All analyses not complete")

dgm_alt<-dgm
outres<-out.results(res=res,dgm=dgm,output.file=output.file,t.min=t.min,out_analysis="FSl")

missC<-tab_tests(res=res)

pA <- as.character(round(outres$pAnyH.approx2,4))
tabsim_missC<-get_tabsim(missC=missC,pA=pA,est_names=est_names,stat_names=stat_names,mod.harm=mod.harm,Nsims=Nsims)

@

\Sexpr{tabsim_missC}


<<r hrh2, echo=TRUE,eval=TRUE>>=
mod.harm <- "alt"
hrH.target <- 2.0

this.dgm<-get.dgm4.OC(mod.harm=mod.harm,N=N,k.treat=k.treat,model.index=model.index,sol_tol=10^-8,
hrH.target=hrH.target,cens.type=cens.type,out.loc=out.loc,file.index=file.index,details=TRUE,parms_torand=FALSE)

dgm<-this.dgm$dgm
output.file<-this.dgm$out.file

if(!is.null(output.file) & !grepl(mod.harm,output.file)) stop("Wrong file name for mod.harm")

# Show first simulation
#ans1 <- oc_analyses_m4_FS4(2)

t.start<-proc.time()[3]
res <- foreach(
    sim = seq_len(Nsims),
    .options.future=list(seed=TRUE),
    .combine="rbind",
    .errorhandling="pass"
  ) %dofuture% {
ans <- oc_analyses_m4FourCuts_FS4(sim)
return(ans)
}
t.now<-proc.time()[3]
t.min<-(t.now-t.start)/60


print(table(res$analysis))
check<-c(c(table(res$analysis))-Nsims)
if(all(check!=0)) stop("All analyses not complete")

dgm_alt<-dgm

outres<-out.results(res=res,dgm=dgm,output.file=output.file,t.min=t.min,out_analysis="FSl")

missC<-tab_tests(res=res)

pA <- as.character(round(outres$pAnyH.approx2,4))

tabsim_missC<-get_tabsim(missC=missC,pA=pA,est_names=est_names,stat_names=stat_names,mod.harm=mod.harm,Nsims=Nsims)

@

\Sexpr{tabsim_missC}


<<echo=TRUE>>=
t.done<-proc.time()[3]
t.min<-(t.done-t.start.all)/60
cat("Minutes and hours to finish",c(t.min,t.min/60),"\n")
cat("Minutes and hours per 10,000 to finish",(10000/Nsims)*c(t.min,t.min/60),"\n")
#cat("Machine=",c(Sys.info()[[4]]),"\n")
#cat("Number of cores=",c(detectCores(logical = FALSE)),"\n")
require(benchmarkme)
my_system <- get_cpu()
my_ram <- get_ram()
cat("Running on system:",c(my_system$model_name),"\n")
cat("with number of cores and cpu/GB=",c(my_system$no_of_cores,round(c(my_ram)/10^9,0)),"\n")
@



\end{document}














