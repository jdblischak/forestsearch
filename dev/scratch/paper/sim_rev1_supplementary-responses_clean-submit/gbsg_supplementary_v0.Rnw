\Sexpr{set_parent("supplementary_SIM-Rev1_v0.Rnw")}


<<echo=FALSE>>=
opts_chunk$set (warning = FALSE, message = FALSE, tidy=TRUE, echo=FALSE, dev = 'pdf')
options(warn=-1)
@

<<echo=FALSE>>=
rm(list=ls())
# For KM plots
codepath<-c("../../R/")
source(paste0(codepath,"source_forestsearch_v0.R"))
source_fs_functions(file_loc=codepath)

library(survival)

gbsg_cens<-round(1-mean(gbsg$status),2)

# This file is created in applications output
# Transfered from output to paper directory
# Older output (first draft)
#load(file="../applications/gbsg/output/gbsg_FSlg_results_boots=2000_v0.Rdata")
# Revised output
load(file="../applications/gbsg/output/gbsg_original_v0.Rdata")
# Analysis dataset
df <- fs.est$df.est

df0.fs<-subset(fs.est$df.pred,treat.recommend==0)
df1.fs<-subset(fs.est$df.pred,treat.recommend==1)
# ITT analysis
cox_itt<-summary(coxph(Surv(time_months,status)~hormon,data=fs.est$df.pred))$conf.int
  # ITT estimates
resITT<-c(round(cox_itt[c(1,3,4)],2),nrow(fs.est$df.pred))
@


<<echo=FALSE,message=FALSE,warning=FALSE>>=
H_estimates <- round(fs_bc$H_estimates,2)
Hc_estimates <- round(fs_bc$Hc_estimates,2)
resH <- unlist(H_estimates[,c("H0","H0_lower","H0_upper")])
resHB <- unlist(H_estimates[,c("H2","H2_lower","H2_upper")])
resHc <- unlist(Hc_estimates[,c("H0","H0_lower","H0_upper")])
resHcB <- unlist(Hc_estimates[,c("H2","H2_lower","H2_upper")])

L_factors <- fs.est$find.grps$L
max_count <- fs.est$find.grps$max_count
sg_loc <- fs.est$grp.consistency$sg.harm.id
SG_hrs <- fs.est$grp.consistency$out_hr$result
p_consistency <- 100*round(SG_hrs$Pcons[sg_loc],3)

# N-fold SGs
SG_tab_Kfold <- summary_OOB$SG_tab_Kfold$res_out
nH_OOB <- SG_tab_Kfold[1,c("n")]
# Full analysis
SG_tab_full <- summary_OOB$SG_tab_original$res_out
nH_full <- SG_tab_full[1,c("n")]

H_nfold <- summary_OOB$SG_tab_Kfold$res_out[1,8]
Hc_nfold <- summary_OOB$SG_tab_Kfold$res_out[2,8]

# Number of SGs found in N-fold
nf_OOB <- round(fs_OOB$prop_SG_found*nrow(df)/100,0)
# Proportion found
pf_OOB <- fs_OOB$prop_SG_found

@



<<echo=FALSE,eval=FALSE>>=
# Output as PDF for more 
# control on formatting
pdf(file = "plot_KM_gbsg_supplementary.pdf",   
width = 10, height = 10) 
library(latex2exp)
par(mfrow=c(1,2))
tte.name<-c("time_months")
event.name<-c("status")
treat.name<-c("hormon")
byrisk <- 12

risk.cex<-0.85
legend.cex<-0.90

df.analysis <- fs.est$df.pred
# Add all events
evs<-sort(unique(df.analysis$time_months[which(df.analysis$status==1)]))
tpoints.add<-c(-1,evs,max(df.analysis$time_months))

# Legend labels for H

Hla<-sprintf(r'($\hat{H}, %s$)',c("Treatment"))
Hlb<-sprintf(r'($\hat{H}, %s$)',c("Control"))
Hl<-c(Hla,Hlb)

Hcla<-sprintf(r'($\hat{H^{c}}, %s$)',c("Treatment"))
Hclb<-sprintf(r'($\hat{H^{c}}, %s$)',c("Control"))
Hcl<-c(Hcla,Hclb)

dfp<-df0.fs

kmH.fit<-KM.plot.2sample.weighted(Y=dfp[,c(tte.name)],E=dfp[,c(event.name)],Treat=dfp[,c(treat.name)],
risk.set=TRUE,by.risk=byrisk,tpoints.add=tpoints.add,risk.cex=risk.cex,
stop.onerror=TRUE,check.KM=TRUE,
Xlab="Months",Ylab="Recurrence-free Survival",details=FALSE,
show.ticks=TRUE,
col.1="black", col.2="blue",
ltys=c(1,2),lwds=c(3,3),
plotit=TRUE, risk_offset=0.10, risk_delta=0.035,
show.logrank=FALSE,show.med=FALSE,show.cox=FALSE)
title(sub="(a) Estrogen = 0 and Prog <= 32.5")

legend("topright",
legend=TeX(Hl),col=c("black","blue"),lwd=c(3,3),lty=c(1,2),bty="n",cex=legend.cex)


dfp<-df1.fs

kmH.fit<-KM.plot.2sample.weighted(Y=dfp[,c(tte.name)],E=dfp[,c(event.name)],Treat=dfp[,c(treat.name)],
risk.set=TRUE,by.risk=byrisk,tpoints.add=tpoints.add,risk.cex=risk.cex,
show.Y.axis=FALSE,
stop.onerror=TRUE, check.KM=TRUE,
Xlab="Months",Ylab="",details=FALSE,
show.ticks=TRUE,
col.1="black", col.2="blue",
ltys=c(1,2),lwds=c(3,3),
plotit=TRUE, risk_offset=0.10, risk_delta=0.035,
show.logrank=FALSE,show.med=FALSE,show.cox=FALSE)
title(sub="(b) Estrogen > 0 or Progesteron > 32.5")

legend("topright",
legend=TeX(Hcl),col=c("black","blue"),lwd=c(3,3),lty=c(1,2),bty="n",cex=legend.cex)

dev.off()
@


\begin{figure}
\begin{center}
\includegraphics[width=\textwidth, height=3.25in]{plot_KM_gbsg_supplementary.pdf}
\end{center}
\caption{GBSG analysis application of Forest Search. Kaplan-Meier (K-M) curves (un-adjusted for the estimation of subgroups): (a) Forest Search $\widehat{H}$ subgroup treatment estimates;
(b) Forest Search $\widehat{H}^{c}$ subgroup K-M treatment estimates.}
\label{fig:gbsgSupp}
\end{figure}


\subsection*{S2.1 GBSG Analysis}

We consider an alternative analysis of the German Breast Cancer Study Group trial data \citep{Schumacher_1994}.   In the analysis of the main text we
employed the selection criterion where the largest subgroup achieving a consistency rate of at least $90\%$ is chosen based on a broad set of candidate baseline factor cuts.  Here we consider the FS 
criterion of maximizing the consistency rate where lasso is utilized in conjunction with GRF (in a less broad manner in comparison to the main text).  Recall the study sample size was $N=\Sexpr{nrow(gbsg)}$ and the observed censoring rate was $\approx \Sexpr{100*gbsg_cens}\%$.  The Cox ITT HR estimate (with only treatment as covariate) is $\Sexpr{resITT[1]}$ ($\Sexpr{resITT[2]}$, $\Sexpr{resITT[3]}$).
There were seven prognostic factors collected: \verb+Estrogen+, \verb+Age+, \verb+Prog+, \verb+Meno+, \verb+Nodes+, \verb+Size+, and \verb+Grade+.   The factors \verb+Meno+ and \verb+Grade+ (\verb+Grade+ defined as grade 1/2 vs 3) are categorical and the rest are continuous. 
The first stage of our algorithm is to apply lasso which selects \verb+Size+, \verb+Grade+, \verb+Nodes+, and \verb+Prog+.  Applying GRF ($\grfb$ with a 6-month RMST criterion) selects \verb+Estrogen<=0+.  Now, the analyses of \cite{Sauerbrei_1999} suggest that \verb+Age+ 
may be prognostic with inflection points at 40 and 55 years (See their Figure 2).  We therefore consider these two cuts as candidates (``forced as candidates'' regardless of lasso and GRF).  In summary, we consider seven candidate factors:  \verb+Size<=median(Size)+; \verb+Nodes<=median(Nodes)+; \verb+Prog<=median(Prog)+; 
\verb+Estrogen<=0+; \verb+Age<=40+; \verb+Age<=55+; and \verb+Grade+.  There are then $L = \Sexpr{L_factors}$ total single factor subgroups with $L*(L-1)/2+L = \Sexpr{max_count}$ possible subgroups (two-factor combinations):  Among these 
subgroups the number of candidates with sample sizes $\geq 60$ and at least $10$ events in each arm is reduced to $68$. 

 The $\fslg$ approach, maximizing consistency, estimates $\widehat{H}$ as the subgroup formed by the combination of \verb+Estrogen<=0+ and \verb+Prog<=32.5+ (The consistency rate is $\Sexpr{p_consistency}\%$).  That is, $\widehat{H}$ subjects are those with an estrogen level of $0$ and progesterone values at or 
 below $\Sexpr{round(with(gbsg,median(pgr)),2)}$ ($n= \Sexpr{nrow(df0.fs)}$).  The resulting $\hat{H}$-estimates are $\hhat = \Sexpr{resH[1]}$ ($\Sexpr{resH[2]}$, $\Sexpr{resH[3]}$) and (bootstrap bias-corrected) $\hhatB =\Sexpr{resHB[1]}$ ($\Sexpr{resHB[2]}$, $\Sexpr{resHB[3]}$).  For the complement, $\hchat = \Sexpr{resHc[1]}$ ($\Sexpr{resHc[2]}$, $\Sexpr{resHc[3]}$) and $\hchatB =\Sexpr{resHcB[1]}$ ($\Sexpr{resHcB[2]}$, $\Sexpr{resHcB[3]}$).  Figure \ref{fig:gbsgSupp} displays the Kaplan-Meier curves for the estimated subgroups.

To evaluate the quality and stability of the subgroup selection algorithm we apply $N$-fold and 10-fold cross-validation as described in the main text.  Recall for $N$-fold 
cross validation we exclude each subject from the analysis and predict their $\widehat{H}$ ($\widehat{H}^{c}$) classification (based on the remaining $n-1$ subjects) where if a subgroup 
is not identified then the subject is classified as $\widehat{H}^{c}$ (i.e., $\widehat{H}= \emptyset$).   In contrast, for 10-fold cross-validation we randomly partition the data into 10 folds and for each fold select $\widehat{H}$ based on the 
remaining 9 folds to predict the classification for the left out fold.  Since this depends on the random partition we repeat this $200$ 
times.

For the $N$-fold cross-validation, across the $n=\Sexpr{nrow(df)}$ training sets (based on deleting a single subject) there were 622 ($\Sexpr{100*round(622/nrow(df),2)}$\%) subgroups identified wherein \verb+Estrogen<=0+ is selected 621 times and \verb+Prog<=32+ and \verb+Prog<=33+ are selected 342 and 260 times (resp.).  Approximately $\Sexpr{100*(1-round(622/nrow(df),2))}$\% of the subjects are classified as ITT:=$\widehat{H}^{c}$ due to lack of subgroup identification and in total $n=40$ subjects ($N$-fold predicted) are classified as $\widehat{H}$ (in contrast to $n=75$ for the full analysis).
Despite the seemingly reasonable agreement between the identified subgroup definitions, the Cox model estimate for the $N$-fold predicted subgroup $\widehat{H}$ is $0.26$ ($0.08, 0.90$) which dramatically differs from the full analysis $\hhatB =\Sexpr{resHB[1]}$ ($\Sexpr{resHB[2]}$, $\Sexpr{resHB[3]}$).  In addition, across $200$ random 10-fold cross-validation analyses the median number of training sets where a subgroup was identified was only 6 out of 10 resulting in a low (median) sensitivity of $sens(\widehat{H}) = 52\%$.  That is, among the $\widehat{H}$-classified subjects based on the full analysis the median percentage also $\widehat{H}$-classified in the (10-fold) cross-validation testing samples is approximately only $50\%$.

In comparison to the analysis of the main text, the FS criterion of maximizing the consistency rate where candidate factors are selected in the above manner does not appear to 
exhibit preferable stability properties for this data application.




