\Sexpr{set_parent("supplementary_SIM-Rev1_v0.Rnw")}


<<echo=FALSE>>=
opts_chunk$set (warning = FALSE, message = FALSE, tidy=TRUE, echo=FALSE, dev = 'pdf')
options(warn=-1)
@
  
 <<echo=FALSE>>=
rm(list=ls())
# For KM plots
codepath<-c("../../R/")
source(paste0(codepath,"source_forestsearch_v0.R"))
source_fs_functions(file_loc=codepath)

library(survival)
library(speff2trial)

load(file="../applications/actg-175/output/actg175_original_v0.Rdata")
# Analysis dataset
df <- fs.est$df.est

df0.fs<-subset(fs.est$df.pred,treat.recommend==0)
df1.fs<-subset(fs.est$df.pred,treat.recommend==1)

# ITT analysis (Reverse treatment roles to original)
cox_itt<-summary(coxph(Surv(time_months,cens)~arm1,data=fs.est$df.pred))$conf.int
  # ITT estimates
resITT<-c(round(cox_itt[c(1,3,4)],2),nrow(fs.est$df.pred))

df0.fs$treat2 <- 1-df0.fs$treat
df1.fs$treat2 <- 1-df1.fs$treat

@
  
  
<<echo=FALSE,message=FALSE,warning=FALSE>>=
H_estimates <- round(fs_bc$H_estimates,2)
Hc_estimates <- round(fs_bc$Hc_estimates,2)

resQ <- unlist(H_estimates[,c("H0","H0_lower","H0_upper")])
resQB <- unlist(H_estimates[,c("H2","H2_lower","H2_upper")])
resQc <- unlist(Hc_estimates[,c("H0","H0_lower","H0_upper")])
resQcB <- unlist(Hc_estimates[,c("H2","H2_lower","H2_upper")])

L_factors <- fs.est$find.grps$L
max_count <- fs.est$find.grps$max_count
sg_loc <- fs.est$grp.consistency$sg.harm.id
SG_hrs <- fs.est$grp.consistency$out_hr$result
# Here, only 1 SG is returned (Need to check this manually)
# Here override sg_loc =1
sg_loc <- 1
p_consistency <- 100*round(SG_hrs$Pcons[sg_loc],3)

# N-fold SGs
SG_tab_Kfold <- summary_OOB$SG_tab_Kfold$res_out
nH_OOB <- SG_tab_Kfold[1,c("n")]
# Full analysis
SG_tab_full <- summary_OOB$SG_tab_original$res_out
nH_full <- SG_tab_full[1,c("n")]

H_nfold <- summary_OOB$SG_tab_Kfold$res_out[1,8]
Hc_nfold <- summary_OOB$SG_tab_Kfold$res_out[2,8]

# Number of SGs found in N-fold
nf_OOB <- round(fs_OOB$prop_SG_found*nrow(df)/100,0)
# Proportion found
pf_OOB <- fs_OOB$prop_SG_found

@
  
<<echo=FALSE,message=FALSE,warning=FALSE,eval=FALSE>>=
# To update, need to re-evaluate (set eval=TRUE)
library(latex2exp)

# Reverse treatment roles to original via treat2
df.analysis <- fs.est$df.pred

pdf(file = "plot_KM_actg_supplementary.pdf", 
width = 10, height = 10) 

par(mfrow=c(1,2))
tte.name<-c("time_months")
event.name<-c("cens")
# Revert back to original treatment 1-vs-3 comparison
treat.name<-c("treat2")
byrisk <- 4

risk.cex<-0.95
legend.cex<-0.90

# Add all events
evs<-sort(unique(df.analysis$time_months[which(df.analysis$cens==1)]))
tpoints.add<-c(-1,evs,max(df.analysis$time_months))

# Legend labels for Q
# Q is "especially strong"

Hla<-sprintf(r'($\hat{Q}, %s$)',c("Treatment"))
Hlb<-sprintf(r'($\hat{Q}, %s$)',c("Control"))
Hl<-c(Hla,Hlb)

Hcla<-sprintf(r'($\hat{Q^{c}}, %s$)',c("Treatment"))
Hclb<-sprintf(r'($\hat{Q^{c}}, %s$)',c("Control"))
Hcl<-c(Hcla,Hclb)

dfp<-df0.fs

kmH.fit<-KM.plot.2sample.weighted(Y=dfp[,c(tte.name)],E=dfp[,c(event.name)],Treat=dfp[,c(treat.name)],
risk.set=TRUE,by.risk=byrisk,tpoints.add=tpoints.add,risk.cex=risk.cex,
choose_ylim=TRUE,
stop.onerror=TRUE, check.KM=TRUE,
Xlab="Months",Ylab="Event-free Survival",details=FALSE,
show.ticks=TRUE,
col.1="black", col.2="blue",
ltys=c(1,2),lwds=c(3,3),
plotit=TRUE,
show.logrank=FALSE,show.med=FALSE,show.cox=FALSE)
title(sub="(a) Preanti <= 406 and Age > 34")

legend("topright",
legend=TeX(Hl),col=c("black","blue"),lwd=c(3,3),lty=c(1,2),bty="n",cex=legend.cex)


dfp<-df1.fs

kmH.fit<-KM.plot.2sample.weighted(Y=dfp[,c(tte.name)],E=dfp[,c(event.name)],Treat=dfp[,c(treat.name)],
risk.set=TRUE,by.risk=byrisk,tpoints.add=tpoints.add,risk.cex=risk.cex,
show.Y.axis=FALSE,
choose_ylim=TRUE,
stop.onerror=TRUE, check.KM=TRUE,
Xlab="Months",Ylab="",details=FALSE,
show.ticks=TRUE,
col.1="black", col.2="blue",
ltys=c(1,2),lwds=c(3,3),
plotit=TRUE,
show.logrank=FALSE,show.med=FALSE,show.cox=FALSE)
title(sub="(b) Preanti > 406 or Age <= 34")

legend("topright",
legend=TeX(Hcl),col=c("black","blue"),lwd=c(3,3),lty=c(1,2),bty="n",cex=legend.cex)

dev.off()

@


\begin{figure}
\begin{center}
\includegraphics[width=\textwidth, height=3.25in]{plot_KM_actg_supplementary.pdf}
\end{center}
\caption{ACTG-175 analysis application of Forest Search. Kaplan-Meier (K-M) curves (un-adjusted for the estimation of subgroups): (a) Forest Search $\widehat{Q}$ subgroup treatment estimates;
(b) Forest Search $\widehat{Q}^{c}$ subgroup K-M treatment estimates.}
\label{fig:KM_actg1}
\end{figure}

\subsection*{S2.2 ACTG-175 Analysis}

We now consider additional analyses of the AIDS Clinical Trials Group Protocol 175 study (\citealp{ACTG175}) where, as in the main text, 
the goal is to identify whether a subgroup exists with a pronounced treatment benefit.  Recall we consider the following fifteen baseline covariates: \verb+Age+, \verb+Wtkg+, \verb+Karnof+ (Karnofsky score), \verb+Cd40+, \verb+Cd80+, \verb+Hemo+ (hemophilia), \verb+HA+ (homosexual activity), 
\verb+Drugs+ (history of IV drug use), \verb+Race+, \verb+Gender+, \verb+Oprior+ (prior anti-viral therapy), \verb+Symptom+, 
\verb+Preanti+ (days prior antiretroviral therapy), \verb+Str2+ (0=naive antiretroviral history,1=experienced), and \verb+Z30+ (zidovudine 30 days prior to study). 

In contrast to the analysis of the main text, here we only consider cuts for continuous factors at the mean or median.  Briefly, the lasso and GRF algorithms lead to the following candidate factors: \verb+Cd40+, \verb+Cd80+, and \verb+Age+ are cut at the medians; \verb+Wtkg<=68.04+, \verb+Age<=29+, \verb+Preanti<=406+, \verb+Karnof<=mean+, \verb+HA+, and \verb+Symptom+ are also included.  Here the mean cut for \verb+Karnof+ and median for \verb+Age+ were ``forced'' as candidates.  Note that the median for \verb+Karnof+ is also the maximum and thus a cut at the median is not viable; And for \verb+Age+, the median (= 34 years) is forced as a candidate since the results of \cite{CZ_2023} suggest an inflection point for age between 30 and 40 years (See their Figure 4).

There are then $L = \Sexpr{L_factors}$ total single factor subgroups with $L*(L-1)/2+L = \Sexpr{max_count}$ possible subgroups:  Among these 
subgroups the number of candidates with sample sizes $\geq 60$ and at least $10$ events in each arm is reduced to $151$. The largest subgroup with a consistency 
rate of at least $90\%$ is the subgroup formed by the combination of \verb+Preanti <= 406+ and \verb+Age > 34+ ($\Sexpr{p_consistency}\%$).  The resulting $\widehat{Q}$-estimates are $\hat\theta(\widehat{Q}) = \Sexpr{resQ[1]}$ ($\Sexpr{resQ[2]}$, $\Sexpr{resQ[3]}$) and (bootstrap bias-corrected) 
$\hat\theta^{*}(\widehat{Q}) =\Sexpr{resQB[1]}$ ($\Sexpr{resQB[2]}$, $\Sexpr{resQB[3]}$).  For the complement, $\hat\theta(\widehat{Q}^{c}) = \Sexpr{resQc[1]}$ ($\Sexpr{resQc[2]}$, $\Sexpr{resQc[3]}$) and $\hat\theta^{*}(\widehat{Q}^{c}) =\Sexpr{resQcB[1]}$ ($\Sexpr{resQcB[2]}$, $\Sexpr{resQcB[3]}$). Figure \ref{fig:KM_actg1} displays the Kaplan-Meier curves for the estimated subgroups.


For the $N$-fold cross-validation, across the $n=\Sexpr{nrow(df)}$ training sets there were 
$\Sexpr{nf_OOB}$ ($\Sexpr{pf_OOB}\%$) subgroups identified wherein the full analysis subgroup $\widehat{Q}$ 
definitions, \verb+Preanti<=406+ and \verb+Age>34+, are reproduced for all (except 1). A total of    
$\Sexpr{round(nrow(df)*(1-(pf_OOB/100)),0)}$ ($\Sexpr{100*(1-round((pf_OOB/100),2))}$\%) subjects were classified as ITT:=$\widehat{Q}^{c}$ due to lack of subgroup identification and in total $n=\Sexpr{nH_OOB}$ subjects ($N$-fold predicted) are classified as $\widehat{Q}$ (versus $n=\Sexpr{nH_full}$ for the full analysis). 
The Cox model estimate for the $N$-fold predicted subgroup $\widehat{Q}$ is $0.45$ [$95\%= 0.25, 0.81$] which is similar 
to the (bootstrap bias-adjusted) full analysis $\hat\theta^{*}(\widehat{Q}) =\Sexpr{resQB[1]}$ ($\Sexpr{resQB[2]}$, $\Sexpr{resQB[3]}$); And for the complement, the $N$-fold predicted subgroup $\widehat{Q}^{c}$ is $1.01$ ($0.76, 1.36$) which is similar 
to the full analysis $\hat\theta^{*}(\widehat{Q}^{c}) =\Sexpr{resQcB[1]}$ ($\Sexpr{resQcB[2]}$, $\Sexpr{resQcB[3]}$).

Across $200$ random 10-fold cross-validation analyses the median number of training sets (10 folds) where a subgroup was identified was only 6 out of 10 (The minimum was 3/10 with lower and upper quartiles of 6/10 and 7/10, resp.) resulting in a low (median) sensitivity of 
$sensCV(\widehat{Q}) = 50\%$.  That is, among the $\widehat{Q}$-classified subjects based on the full analysis the median percentage also $\widehat{Q}$-classified in the (10-fold) cross-validation testing samples is approximately only $50\%$.  The median positive predictive value was 
$ppvCV(\widehat{Q}) \approx 69\%$. For the complement $\widehat{Q}^{c}$, the medians for $sensCV$ and $ppvCV$ were $91\%$ and $82\%$, respectively.  In addition, across the $200$ random 10-fold cross-validation analyses, the exact $\hat{Q}$ subgroup definition of \verb+Preanti<=406+ and \verb+Age>34+ was exactly reproduced $20\%$ of the time (median), while definitions based on (cuts of) \verb+Preanti+ and \verb+Age+ appeared (a median of) $40\%$ and $50\%$ of the time, respectively (and jointly $40\%$).   Although the subgroup estimates are similar to the analysis of the main text, the 
CV properties are substantially less favorable.  We conjecture that this is due to the FS analysis of the main text incorporating a broader set of baseline factor cuts. 

The computational timing on an Apple M1 20 core with 69 GB was approximately: $0.2$ minutes for the FS analysis; $20$ minutes for the $2000$ Bootstraps; $\Sexpr{round(fs_OOB$timing_minutes,0)}$ minutes for the $N$-fold cross-validation; and $\approx
\Sexpr{round(tall.min-31.675,0)}$ minutes for the $200$ random 10-fold cross-validation analyses.  In total, the number of minutes was $\approx \Sexpr{round(tall.min,0)}$.


  